#!/usr/bin/env python3
"""
LinkedIn Multi-Organization Follower Statistics Tracker
Ce script collecte les statistiques des followers LinkedIn par cat√©gorie (industrie, fonction, s√©niorit√©, etc.)
pour plusieurs organisations et les enregistre dans Google Sheets avec un formatage optimis√© pour Looker Studio.
"""

import os
import requests
import urllib.parse
import json
from datetime import datetime
import time
from pathlib import Path
import sys
from dotenv import load_dotenv
import random

# Pour Google Sheets
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from gspread.exceptions import APIError

# Chargement des variables d'environnement
load_dotenv()

def ensure_percentage_as_decimal(value):
    """
    Convertit une valeur en d√©cimal pour Google Sheets PERCENT
    
    Args:
        value: La valeur √† convertir (peut √™tre 5 pour 5% ou 0.05 pour 5%)
    
    Returns:
        float: Valeur en d√©cimal (0.05 pour 5%)
    """
    if value is None:
        return 0.0
    
    if isinstance(value, str):
        # Enlever le symbole % si pr√©sent
        value = value.replace('%', '').strip()
        try:
            value = float(value)
        except:
            return 0.0
    
    if isinstance(value, (int, float)):
        # Si la valeur est > 1, on assume que c'est un pourcentage
        if value > 1:
            return float(value / 100)
        else:
            return float(value)
    
    return 0.0


def safe_sheets_operation(operation, *args, max_retries=5, **kwargs):
    """
    Ex√©cute une op√©ration Google Sheets avec gestion des erreurs de quota et de service
    """
    for attempt in range(max_retries):
        try:
            return operation(*args, **kwargs)
        except APIError as e:
            error_code = str(e)
            
            # Gestion des diff√©rents types d'erreurs
            if '429' in error_code or 'Quota exceeded' in error_code:
                # Quota d√©pass√©
                base_delay = min(60, (2 ** attempt) * 5)
                jitter = random.uniform(0.5, 1.5)
                delay = base_delay * jitter
                print(f"   ‚è≥ Quota d√©pass√© (tentative {attempt + 1}/{max_retries}), attente de {delay:.1f}s...")
                time.sleep(delay)
            elif '503' in error_code or 'unavailable' in error_code.lower():
                # Service indisponible
                base_delay = min(120, (2 ** attempt) * 10)
                jitter = random.uniform(0.8, 1.2)
                delay = base_delay * jitter
                print(f"   üîÑ Service Google Sheets indisponible (tentative {attempt + 1}/{max_retries}), attente de {delay:.1f}s...")
                time.sleep(delay)
            elif '500' in error_code or '502' in error_code or '504' in error_code:
                # Erreurs serveur
                base_delay = min(60, (2 ** attempt) * 8)
                jitter = random.uniform(0.7, 1.3)
                delay = base_delay * jitter
                print(f"   üîß Erreur serveur Google (tentative {attempt + 1}/{max_retries}), attente de {delay:.1f}s...")
                time.sleep(delay)
            else:
                print(f"   ‚ùå Erreur API non g√©r√©e: {e}")
                if attempt == max_retries - 1:
                    raise
                time.sleep(5)
                
            if attempt == max_retries - 1:
                print(f"   ‚ùå √âchec apr√®s {max_retries} tentatives: {e}")
                raise
                
        except Exception as e:
            print(f"   ‚ùå Erreur inattendue: {e}")
            if attempt == max_retries - 1:
                raise
            # Attendre un peu avant de r√©essayer
            time.sleep(min(30, (2 ** attempt) * 2))

class LinkedInFollowerStatisticsTracker:
    """Classe pour suivre les statistiques des followers LinkedIn par cat√©gorie"""
    
    def __init__(self, access_token, organization_id, sheet_name=None):
        """Initialise le tracker avec le token d'acc√®s et l'ID de l'organisation"""
        self.access_token = access_token
        self.organization_id = organization_id
        self.sheet_name = sheet_name or f"LinkedIn_Follower_Stats_{organization_id}"
        self.base_url = "https://api.linkedin.com/rest"
        
    def get_headers(self):
        """Retourne les en-t√™tes pour les requ√™tes API"""
        return {
            "Authorization": f"Bearer {self.access_token}",
            "X-Restli-Protocol-Version": "2.0.0",
            "LinkedIn-Version": "202505",
            "Content-Type": "application/json"
        }
    
    def get_follower_statistics(self):
        """Obtient les statistiques de followers pour l'organisation"""
        # Encoder l'URN de l'organisation
        organization_urn = f"urn:li:organization:{self.organization_id}"
        encoded_urn = urllib.parse.quote(organization_urn)
        
        # Construire l'URL
        url = f"{self.base_url}/organizationalEntityFollowerStatistics?q=organizationalEntity&organizationalEntity={encoded_urn}"
        
        # Effectuer la requ√™te avec gestion des erreurs et retry
        max_retries = 3
        retry_delay = 2  # secondes
        
        for attempt in range(max_retries):
            try:
                response = requests.get(url, headers=self.get_headers())
                
                if response.status_code == 200:
                    data = response.json()
                    print(f"   Donn√©es statistiques r√©cup√©r√©es avec succ√®s")
                    return data
                    
                elif response.status_code == 429:
                    # Rate limit, attendre avant de r√©essayer
                    print(f"   Rate limit atteint, attente de {retry_delay} secondes...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Backoff exponentiel
                else:
                    print(f"   Erreur API: {response.status_code} - {response.text}")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    
            except Exception as e:
                print(f"   Exception lors de la requ√™te: {e}")
                time.sleep(retry_delay)
                retry_delay *= 2
        
        print("   √âchec apr√®s plusieurs tentatives pour obtenir les statistiques des followers.")
        return None
        
    def _get_total_followers(self):
        """R√©cup√®re le nombre total de followers via plusieurs m√©thodes"""
        
        # M√©thode 1: Via networkSizes (m√©thode document√©e)
        total_followers = self._get_total_via_network_sizes()
        if total_followers > 0:
            return total_followers
            
        # M√©thode 2: Via organizations (si on a les droits admin)
        total_followers = self._get_total_via_organizations()
        if total_followers > 0:
            return total_followers
            
        # M√©thode 3: Calculer depuis les statistiques existantes (moins pr√©cis)
        print("   ‚ö†Ô∏è  Impossible de r√©cup√©rer le total r√©el, utilisation du calcul approximatif")
        return 0
    
    def _get_total_via_network_sizes(self):
        """R√©cup√®re le nombre total via l'API networkSizes (m√©thode document√©e)"""
        try:
            # Selon la doc, l'URL doit √™tre exactement comme √ßa
            organization_urn = f"urn:li:organization:{self.organization_id}"
            encoded_urn = urllib.parse.quote(organization_urn, safe='')
            
            # URL exacte selon la documentation
            url = f"{self.base_url}/networkSizes/{encoded_urn}?edgeType=COMPANY_FOLLOWED_BY_MEMBER"
            
            response = requests.get(url, headers=self.get_headers())
            
            if response.status_code == 200:
                data = response.json()
                followers = data.get('firstDegreeSize', 0)
                if followers > 0:
                    print(f"   Nombre total de followers: {followers}")
                    return followers
            else:
                # Si √ßa ne marche pas, essayer l'ancienne notation
                url_old = f"{self.base_url}/networkSizes/{encoded_urn}?edgeType=CompanyFollowedByMember"
                response = requests.get(url_old, headers=self.get_headers())
                
                if response.status_code == 200:
                    data = response.json()
                    followers = data.get('firstDegreeSize', 0)
                    if followers > 0:
                        print(f"   Nombre total de followers: {followers}")
                        return followers
                
        except Exception as e:
            print(f"   Exception avec networkSizes: {e}")
            
        return 0
    
    def _get_total_via_organizations(self):
        """R√©cup√®re le nombre total via l'API organizations (n√©cessite droits admin)"""
        try:
            # Essayer avec l'ID direct (n√©cessite droits admin)
            url = f"{self.base_url}/organizations/{self.organization_id}"
            
            response = requests.get(url, headers=self.get_headers())
            
            if response.status_code == 200:
                data = response.json()
                # Chercher followerCount dans la r√©ponse
                # Note: Ce champ n'est pas document√© dans la doc fournie, mais peut exister
                followers = data.get('followerCount', 0)
                if followers > 0:
                    print(f"   Nombre total de followers (via organizations): {followers}")
                    return followers
            
        except Exception as e:
            print(f"   Exception avec organizations: {e}")
            
        return 0
    
    def parse_follower_statistics(self, data):
        """Analyse les donn√©es de l'API et extrait les statistiques pertinentes"""
        stats = {}
        
        # Date de r√©cup√©ration
        stats['date'] = datetime.now().strftime('%Y-%m-%d')
        
        # S'assurer que les donn√©es sont valides
        if not data or 'elements' not in data or len(data['elements']) == 0:
            print("   Aucune donn√©e de statistiques valide trouv√©e.")
            stats['total_followers'] = 0
            stats['by_company_size'] = {'Non sp√©cifi√©': {'numeric_size': 999999, 'organic': 0, 'paid': 0, 'total': 0}}
            stats['by_function'] = {'0': {'name': 'Non sp√©cifi√©', 'organic': 0, 'paid': 0, 'total': 0}}
            stats['by_seniority'] = {'0': {'name': 'Non sp√©cifi√©', 'organic': 0, 'paid': 0, 'total': 0}}
            stats['by_industry'] = {'0': {'name': 'Non sp√©cifi√©', 'organic': 0, 'paid': 0, 'total': 0}}
            return stats
        
        # Obtenir le premier √©l√©ment (qui contient toutes les stats)
        element = data['elements'][0]
        
        # D'abord, calculer les totaux pour chaque cat√©gorie
        # Car LinkedIn peut avoir des followers compt√©s dans plusieurs cat√©gories
        totals_by_category = {
            'size': 0,
            'function': 0,
            'seniority': 0,
            'industry': 0
        }
        
        # Calculer le total depuis les tailles d'entreprise
        if 'followerCountsByStaffCountRange' in element:
            for item in element['followerCountsByStaffCountRange']:
                organic_count = item.get('followerCounts', {}).get('organicFollowerCount', 0)
                paid_count = item.get('followerCounts', {}).get('paidFollowerCount', 0)
                totals_by_category['size'] += (organic_count + paid_count)
        
        # Calculer le total depuis les fonctions
        if 'followerCountsByFunction' in element:
            for item in element['followerCountsByFunction']:
                organic_count = item.get('followerCounts', {}).get('organicFollowerCount', 0)
                paid_count = item.get('followerCounts', {}).get('paidFollowerCount', 0)
                totals_by_category['function'] += (organic_count + paid_count)
        
        # Calculer le total depuis les s√©niorit√©s
        if 'followerCountsBySeniority' in element:
            for item in element['followerCountsBySeniority']:
                organic_count = item.get('followerCounts', {}).get('organicFollowerCount', 0)
                paid_count = item.get('followerCounts', {}).get('paidFollowerCount', 0)
                totals_by_category['seniority'] += (organic_count + paid_count)
        
        # Calculer le total depuis les industries
        if 'followerCountsByIndustry' in element:
            for item in element['followerCountsByIndustry']:
                organic_count = item.get('followerCounts', {}).get('organicFollowerCount', 0)
                paid_count = item.get('followerCounts', {}).get('paidFollowerCount', 0)
                totals_by_category['industry'] += (organic_count + paid_count)
        
        # Le total calcul√© est le maximum des totaux par cat√©gorie
        # Car un follower peut √™tre dans toutes les cat√©gories
        calculated_total = max(totals_by_category.values()) if totals_by_category.values() else 0
        
        # Essayer de r√©cup√©rer le nombre total r√©el de followers
        total_followers = self._get_total_followers()
        
        # Si on n'a pas pu r√©cup√©rer le total r√©el, utiliser le total calcul√©
        if total_followers == 0:
            total_followers = calculated_total
            print(f"   ‚ö†Ô∏è  Utilisation du total calcul√© depuis les cat√©gories: {total_followers}")
        
        stats['total_followers'] = total_followers
        
        # Extraire les statistiques par taille d'entreprise
        stats['by_company_size'] = {}
        categorized_by_size = 0
        if 'followerCountsByStaffCountRange' in element:
            for item in element['followerCountsByStaffCountRange']:
                size_range = self._format_company_size(item.get('staffCountRange', ''))
                numeric_size = self._get_numeric_size(size_range)
                organic_count = item.get('followerCounts', {}).get('organicFollowerCount', 0)
                paid_count = item.get('followerCounts', {}).get('paidFollowerCount', 0)
                total_count = organic_count + paid_count
                categorized_by_size += total_count
                stats['by_company_size'][size_range] = {
                    'numeric_size': numeric_size,
                    'organic': organic_count,
                    'paid': paid_count,
                    'total': total_count
                }
        
        # Pour les "Non sp√©cifi√©s", utiliser la diff√©rence avec le total de cette cat√©gorie
        # plut√¥t qu'avec le total g√©n√©ral
        uncategorized_by_size = max(0, total_followers - totals_by_category['size'])
        if uncategorized_by_size > 0 or len(stats['by_company_size']) == 0:
            stats['by_company_size']['Non sp√©cifi√©'] = {
                'numeric_size': 999999,
                'organic': uncategorized_by_size,
                'paid': 0,
                'total': uncategorized_by_size
            }
        
        # Extraire les statistiques par fonction
        stats['by_function'] = {}
        function_descriptions = self._get_function_descriptions()
        categorized_by_function = 0
        if 'followerCountsByFunction' in element:
            for item in element['followerCountsByFunction']:
                function = item.get('function', '')
                function_id = function.split(':')[-1] if ':' in function else function
                function_name = function_descriptions.get(function_id, f"Fonction {function_id}")
                organic_count = item.get('followerCounts', {}).get('organicFollowerCount', 0)
                paid_count = item.get('followerCounts', {}).get('paidFollowerCount', 0)
                total_count = organic_count + paid_count
                categorized_by_function += total_count
                stats['by_function'][function_id] = {
                    'name': function_name,
                    'organic': organic_count,
                    'paid': paid_count,
                    'total': total_count
                }
        
        uncategorized_by_function = max(0, total_followers - totals_by_category['function'])
        if uncategorized_by_function > 0 or len(stats['by_function']) == 0:
            stats['by_function']['0'] = {
                'name': 'Non sp√©cifi√©',
                'organic': uncategorized_by_function,
                'paid': 0,
                'total': uncategorized_by_function
            }
                
        # Extraire les statistiques par anciennet√©
        stats['by_seniority'] = {}
        seniority_descriptions = self._get_seniority_descriptions()
        categorized_by_seniority = 0
        if 'followerCountsBySeniority' in element:
            for item in element['followerCountsBySeniority']:
                seniority = item.get('seniority', '')
                seniority_id = seniority.split(':')[-1] if ':' in seniority else seniority
                seniority_name = seniority_descriptions.get(seniority_id, f"Niveau {seniority_id}")
                organic_count = item.get('followerCounts', {}).get('organicFollowerCount', 0)
                paid_count = item.get('followerCounts', {}).get('paidFollowerCount', 0)
                total_count = organic_count + paid_count
                categorized_by_seniority += total_count
                stats['by_seniority'][seniority_id] = {
                    'name': seniority_name,
                    'organic': organic_count,
                    'paid': paid_count,
                    'total': total_count
                }
        
        uncategorized_by_seniority = max(0, total_followers - totals_by_category['seniority'])
        if uncategorized_by_seniority > 0 or len(stats['by_seniority']) == 0:
            stats['by_seniority']['0'] = {
                'name': 'Non sp√©cifi√©',
                'organic': uncategorized_by_seniority,
                'paid': 0,
                'total': uncategorized_by_seniority
            }
                
        # Extraire les statistiques par industrie
        stats['by_industry'] = {}
        industry_descriptions = self._get_industry_descriptions()
        categorized_by_industry = 0
        if 'followerCountsByIndustry' in element:
            for item in element['followerCountsByIndustry']:
                industry = item.get('industry', '')
                industry_id = industry.split(':')[-1] if ':' in industry else industry
                industry_name = industry_descriptions.get(industry_id, f"Industrie {industry_id}")
                organic_count = item.get('followerCounts', {}).get('organicFollowerCount', 0)
                paid_count = item.get('followerCounts', {}).get('paidFollowerCount', 0)
                total_count = organic_count + paid_count
                categorized_by_industry += total_count
                stats['by_industry'][industry_id] = {
                    'name': industry_name,
                    'organic': organic_count,
                    'paid': paid_count,
                    'total': total_count
                }
        
        uncategorized_by_industry = max(0, total_followers - totals_by_category['industry'])
        if uncategorized_by_industry > 0 or len(stats['by_industry']) == 0:
            stats['by_industry']['0'] = {
                'name': 'Non sp√©cifi√©',
                'organic': uncategorized_by_industry,
                'paid': 0,
                'total': uncategorized_by_industry
            }
        
        # Afficher un r√©sum√© des cat√©gories
        print(f"\n   üìä R√©sum√© des followers:")
        print(f"      Total r√©el/calcul√©: {total_followers}")
        print(f"      Total par taille d'entreprise: {totals_by_category['size']}")
        print(f"      Total par fonction: {totals_by_category['function']}")
        print(f"      Total par s√©niorit√©: {totals_by_category['seniority']}")
        print(f"      Total par industrie: {totals_by_category['industry']}")
        
        return stats
    
    def _get_numeric_size(self, size_range):
        """Extrait la valeur num√©rique maximale de la taille d'entreprise"""
        size_mapping = {
            '1 employ√©': 1,
            '2-10 employ√©s': 10,
            '11-50 employ√©s': 50,
            '51-200 employ√©s': 200,
            '201-500 employ√©s': 500,
            '501-1000 employ√©s': 1000,
            '1001-5000 employ√©s': 5000,
            '5001-10000 employ√©s': 10000,
            '10001+ employ√©s': 10001,
            'Non sp√©cifi√©': 999999
        }
        return size_mapping.get(size_range, 0)
    
    def _get_function_descriptions(self):
        """Fournit une description pour les identifiants de fonction"""
        return {
            "1": "Comptabilit√©",
            "2": "Administration",
            "3": "Arts et design",
            "4": "Commercial",
            "5": "Support client√®le",
            "6": "√âducation",
            "7": "Ing√©nierie",
            "8": "Finance",
            "9": "Sant√©",
            "10": "Ressources humaines",
            "11": "Technologies de l'information",
            "12": "Juridique",
            "13": "Marketing",
            "14": "M√©dias et communication",
            "15": "Militaire et forces de l'ordre",
            "16": "Op√©rations",
            "17": "Autre",
            "18": "Gestion de produit",
            "19": "Achat",
            "20": "Immobilier",
            "21": "Recherche",
            "22": "Vente",
            "23": "Services sociaux",
            "24": "Support",
            "25": "Gestion de programme",
            "26": "Qualit√©"
        }
    
    def _get_seniority_descriptions(self):
        """Fournit une description pour les niveaux de s√©niorit√©"""
        return {
            "1": "Stagiaire",
            "2": "D√©butant",
            "3": "Junior",
            "4": "Interm√©diaire",
            "5": "Senior",
            "6": "Chef d'√©quipe",
            "7": "Directeur",
            "8": "Vice-pr√©sident",
            "9": "C-suite",
            "10": "Cadre dirigeant"
        }
    
    def _get_industry_descriptions(self):
        """Fournit une description pour les identifiants d'industrie LinkedIn"""
        return {
            "1": "Agriculture",
            "2": "√âlevage",
            "3": "P√™che et aquaculture",
            "4": "Banque",
            "5": "Services de t√©l√©communications",
            "6": "Construction",
            "7": "Coop√©ratives",
            "8": "√âducation pr√©scolaire et primaire",
            "9": "√âducation coll√©giale",
            "10": "√âducation secondaire",
            "11": "√âducation",
            "12": "Divertissement",
            "13": "Environnement",
            "14": "Finance",
            "15": "Gouvernement",
            "16": "Sant√©",
            "17": "Industrie manufacturi√®re",
            "18": "M√©dias",
            "19": "Mines et m√©taux",
            "20": "Commerce de d√©tail",
            "21": "Transport",
            "22": "Sports",
            "23": "√âlectronique",
            "24": "√ânergie",
            "25": "H√¥pitaux et sant√©",
            "26": "Assurance",
            "27": "Technologies et services de l'information",
            "28": "Luxe et bijoux",
            "29": "Machinerie",
            "30": "Maritime",
            "31": "Sant√© et bien-√™tre",
            "32": "Services juridiques",
            "33": "Biblioth√®ques",
            "34": "Logistique et cha√Æne d'approvisionnement",
            "35": "Mat√©riaux",
            "36": "Industrie militaire",
            "37": "Industrie musicale",
            "38": "Nanotechnologie",
            "39": "Journaux",
            "40": "Organisation √† but non lucratif",
            "41": "P√©trole et √©nergie",
            "42": "Services en ligne",
            "43": "Outsourcing/Offshoring",
            "44": "Emballage et conteneurs",
            "45": "Papier et produits forestiers",
            "46": "Services philanthropiques",
            "47": "Photographie",
            "48": "Marketing et publicit√©",
            "49": "Imprimerie",
            "50": "Biens de consommation",
            "51": "√âdition",
            "52": "Chemins de fer",
            "53": "Organisation √† but non lucratif",
            "54": "Recherche",
            "55": "Restaurants",
            "56": "S√©curit√© et investigations",
            "57": "Semi-conducteurs",
            "58": "Transport maritime",
            "59": "Textiles",
            "60": "Mode et v√™tements",
            "61": "Arts",
            "62": "Fabrication de moteurs de v√©hicules",
            "63": "Vins et spiritueux",
            "64": "Industrie du fil et de la fibre",
            "65": "Industrie a√©ronautique et a√©rospatiale",
            "66": "Automobile",
            "67": "G√©nie civil",
            "68": "Comptabilit√©",
            "69": "Services financiers",
            "70": "Aviation",
            "71": "Architecture et urbanisme",
            "72": "Biotechnologie",
            "73": "Construction navale",
            "74": "Produits chimiques",
            "75": "Internet",
            "76": "√âquipements √©lectriques/√©lectroniques",
            "77": "Gestion de l'environnement",
            "78": "Produits alimentaires",
            "79": "Collecte de fonds",
            "80": "Jeux vid√©o et √©lectroniques",
            "81": "H√¥tellerie",
            "82": "Mobilier d'entreprise",
            "83": "Intelligence artificielle",
            "84": "Industrie pharmaceutique",
            "85": "Plastiques",
            "86": "Commerce international et d√©veloppement",
            "87": "Industrie du vin et des spiritueux",
            "88": "Commerce de gros",
            "89": "√âlevage d'animaux",
            "90": "Gestion des march√©s",
            "91": "Affaires politiques",
            "92": "Ressources humaines",
            "93": "Industrie laiti√®re",
            "94": "Design",
            "95": "Services aux consommateurs",
            "96": "Logiciels informatiques",
            "97": "√âv√©nements",
            "98": "Arts et artisanat",
            "99": "Formation professionnelle et coaching",
            "100": "Affaires gouvernementales",
            "101": "Meubles",
            "102": "√âquipement de loisir",
            "103": "Mat√©riel de bureau",
            "104": "R√©seaux informatiques",
            "105": "Relations publiques et communications",
            "106": "Activit√©s de loisirs",
            "107": "Immobilier",
            "108": "√âquipement sportif",
            "109": "Vente en gros",
            "110": "Services publics",
            "111": "Animation",
            "112": "Produits cosm√©tiques",
            "113": "≈íuvres de bienfaisance",
            "114": "Industrie du b√©tail",
            "115": "Arts de la sc√®ne",
            "116": "Gestion des installations",
            "117": "Design graphique",
            "118": "√âquipement m√©dical",
            "119": "Conseil",
            "120": "Industrie du bois",
            "121": "Industrie de la construction",
            "122": "Enseignement sup√©rieur",
            "123": "Promotion immobili√®re",
            "124": "Gestion de placements",
            "125": "Services m√©dicaux",
            "126": "Services v√©t√©rinaires",
            "127": "Commerce de d√©tail",
            "128": "G√©nie √©lectrique",
            "129": "Informatique et r√©seau de s√©curit√©",
            "130": "Mat√©riel informatique",
            "131": "B√¢timent et travaux publics",
            "132": "Traduction et localisation",
            "133": "Programmation informatique",
            "134": "Architecture",
            "135": "Relations publiques et communications",
            "136": "Exploitation mini√®re",
            "137": "Design",
            "138": "Sant√©, bien-√™tre et fitness",
            "139": "E-learning",
            "140": "Services bancaires d'investissement",
            "141": "Mus√©es et institutions",
            "142": "V√©t√©rinaire",
            "143": "Industrie du voyage",
            "144": "Technologies de l'information et services",
            "145": "Gestion de l'√©ducation",
            "453": "M√©dias en ligne",
            "840": "Distribution alimentaire",
            "1212": "Recherche et d√©veloppement",
            "1324": "T√©l√©travail",
            "1359": "Capital-risque",
            "1623": "Logiciels open source",
            "1673": "√âquipement informatique",
            "1862": "Sant√© num√©rique",
            "1965": "Assurtech",
            "2029": "Fintech",
            "2353": "D√©veloppement durable",
            "3128": "√ânergie renouvelable",
            "3240": "Intelligence artificielle g√©n√©rative",
            "3241": "Blockchain"
        }
        
    def _format_company_size(self, size_code):
        """Convertit les codes de taille d'entreprise en √©tiquettes lisibles"""
        size_map = {
            'SIZE_1': '1 employ√©',
            'SIZE_2_TO_10': '2-10 employ√©s',
            'SIZE_11_TO_50': '11-50 employ√©s',
            'SIZE_51_TO_200': '51-200 employ√©s',
            'SIZE_201_TO_500': '201-500 employ√©s',
            'SIZE_501_TO_1000': '501-1000 employ√©s',
            'SIZE_1001_TO_5000': '1001-5000 employ√©s',
            'SIZE_5001_TO_10000': '5001-10000 employ√©s',
            'SIZE_10001_OR_MORE': '10001+ employ√©s'
        }
        return size_map.get(size_code, size_code)


class GoogleSheetsExporter:
    """Classe pour exporter les donn√©es vers Google Sheets avec formatage optimis√© pour Looker Studio"""
    
    def __init__(self, spreadsheet_name, credentials_path, admin_email="byteberry.analytics@gmail.com"):
        """Initialise l'exportateur avec le nom du spreadsheet et le chemin des credentials"""
        self.spreadsheet_name = spreadsheet_name
        self.credentials_path = credentials_path
        self.admin_email = admin_email
        self.client = None
        self.spreadsheet = None
        
    def connect(self):
        """√âtablit la connexion avec Google Sheets API"""
        try:
            scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
            creds = ServiceAccountCredentials.from_json_keyfile_name(str(self.credentials_path), scope)
            self.client = gspread.authorize(creds)
            
            # V√©rifier si le spreadsheet existe d√©j√†, sinon le cr√©er
            try:
                self.spreadsheet = self.client.open(self.spreadsheet_name)
                print(f"   Spreadsheet existant trouv√©: {self.spreadsheet_name}")
            except gspread.exceptions.SpreadsheetNotFound:
                self.spreadsheet = safe_sheets_operation(self.client.create, self.spreadsheet_name)
                print(f"   Nouveau spreadsheet cr√©√©: {self.spreadsheet_name}")
                
                # Donner l'acc√®s en √©dition √† l'adresse e-mail sp√©cifi√©e
                safe_sheets_operation(self.spreadsheet.share, self.admin_email, perm_type="user", role="writer")
                print(f"   Acc√®s en √©dition accord√© √† {self.admin_email}")
            
            # V√©rifier si Sheet1 existe et le renommer en "R√©sum√©"
            try:
                sheet1 = self.spreadsheet.worksheet("Sheet1")
                safe_sheets_operation(sheet1.update_title, "R√©sum√©")
                print("   Feuille 'Sheet1' renomm√©e en 'R√©sum√©'")
            except gspread.exceptions.WorksheetNotFound:
                pass  # Sheet1 n'existe pas, pas besoin de la renommer
            
            return True
        except Exception as e:
            print(f"   Erreur de connexion √† Google Sheets: {e}")
            return False
    
    def ensure_admin_access(self):
        """V√©rifie et garantit que l'admin a toujours acc√®s au document"""
        try:
            # R√©cup√©rer les permissions actuelles
            permissions = safe_sheets_operation(self.spreadsheet.list_permissions)
            
            # V√©rifier si l'email admin est d√©j√† dans les permissions
            admin_has_access = False
            for permission in permissions:
                if 'emailAddress' in permission and permission['emailAddress'] == self.admin_email:
                    admin_has_access = True
                    # V√©rifier si le r√¥le est au moins "writer"
                    if permission.get('role') not in ['writer', 'owner']:
                        # Mettre √† jour le r√¥le si n√©cessaire
                        safe_sheets_operation(self.spreadsheet.share, self.admin_email, perm_type="user", role="writer")
                        print(f"   R√¥le mis √† jour pour {self.admin_email} (writer)")
                    break
            
            # Si l'admin n'a pas encore acc√®s, lui donner
            if not admin_has_access:
                safe_sheets_operation(self.spreadsheet.share, self.admin_email, perm_type="user", role="writer")
                print(f"   Acc√®s en √©dition accord√© √† {self.admin_email}")
                
        except Exception as e:
            print(f"   Erreur lors de la v√©rification des permissions: {e}")
    
    def prepare_and_update_summary_sheet(self, stats):
        """Pr√©pare et met √† jour la feuille de r√©sum√© des statistiques avec formatage optimis√© pour Looker"""
        try:
            # V√©rifier si la R√©sum√© existe et l'utiliser en priorit√©
            try:
                sheet = self.spreadsheet.worksheet("R√©sum√©")
                print("   Feuille 'R√©sum√©' utilis√©e pour le r√©sum√©")
            except gspread.exceptions.WorksheetNotFound:
                try:
                    sheet = self.spreadsheet.worksheet("Sheet1")
                    safe_sheets_operation(sheet.update_title, "R√©sum√©")
                    print("   Feuille par d√©faut 'Sheet1' renomm√©e en 'R√©sum√©'")
                except gspread.exceptions.WorksheetNotFound:
                    try:
                        sheet = self.spreadsheet.worksheet("Feuille1")
                        safe_sheets_operation(sheet.update_title, "R√©sum√©")
                        print("   Feuille par d√©faut 'Feuille1' renomm√©e en 'R√©sum√©'")
                    except gspread.exceptions.WorksheetNotFound:
                        sheet = safe_sheets_operation(self.spreadsheet.add_worksheet, title="R√©sum√©", rows=100, cols=10)
                        print("   Nouvelle feuille 'R√©sum√©' cr√©√©e")
            
            # Nettoyer la feuille existante
            safe_sheets_operation(sheet.clear)
            time.sleep(2)
            
            # Utiliser le total r√©el r√©cup√©r√© de l'API
            total_followers = stats.get('total_followers', 0)
            
            # Pr√©parer les donn√©es pour la taille d'entreprise
            company_size_data = []
            # Ajouter l'en-t√™te avec Date
            company_size_data.append(['Date', 'Entreprise jusqu\'√† X employ√©s', 'Nombre de Followers', 'Pourcentage'])
            
            # Date actuelle
            date_str = stats.get('date', datetime.now().strftime('%Y-%m-%d'))
            
            # Convertir et trier par taille num√©rique
            size_data = []
            for size, stats_data in stats['by_company_size'].items():
                numeric_size = stats_data.get('numeric_size', 0)
                followers = stats_data['total']  # Utiliser total au lieu de organic seulement
                # S'assurer que le pourcentage est en d√©cimal
                percentage = float(followers / total_followers) if total_followers > 0 else 0.0
                size_data.append((numeric_size, size, followers, percentage))
            
            # Trier par taille d'entreprise (ordre croissant)
            size_data.sort(key=lambda x: x[0])
            
            # Ajouter √† la liste de donn√©es avec la date
            for _, size_name, followers, percentage in size_data:
                company_size_data.append([date_str, size_name, followers, percentage])  # Pourcentage en d√©cimal
            
            # Ajouter le total avec la date
            company_size_data.append([date_str, 'Total', total_followers, 1.0])  # 100% en d√©cimal
            
            # Mettre √† jour la feuille avec les donn√©es
            safe_sheets_operation(sheet.update, company_size_data, 'A1')
            time.sleep(1)
            
            # FORMATAGE OPTIMIS√â POUR LOOKER STUDIO
            # Formater les en-t√™tes
            safe_sheets_operation(sheet.format, "A1:D1", {
                "textFormat": {"bold": True},
                "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9}
            })
            time.sleep(1)
            
            # Formater la colonne Date (A) comme DATE
            safe_sheets_operation(sheet.format, "A2:A" + str(len(company_size_data)), {
                "numberFormat": {"type": "DATE", "pattern": "yyyy-mm-dd"}
            })
            time.sleep(1)
            
            # Formater la colonne des nombres (C) comme NUMBER
            safe_sheets_operation(sheet.format, "C2:C" + str(len(company_size_data)), {
                "numberFormat": {"type": "NUMBER", "pattern": "#,##0"}
            })
            time.sleep(1)
            
            # Formater la colonne des pourcentages (D) comme PERCENT
            safe_sheets_operation(sheet.format, "D2:D" + str(len(company_size_data)), {
                "numberFormat": {"type": "PERCENT", "pattern": "0.0%"}
            })
            time.sleep(1)
            
            # Formater la ligne de total
            safe_sheets_operation(sheet.format, f"A{len(company_size_data)}:D{len(company_size_data)}", {
                "textFormat": {"bold": True}
            })
            
            return sheet
        except Exception as e:
            print(f"   Erreur lors de la pr√©paration de la feuille de r√©sum√©: {e}")
            return None
    
    def prepare_and_update_detail_sheets(self, stats):
        """Pr√©pare et met √† jour les feuilles d√©taill√©es pour chaque cat√©gorie"""
        try:
            # Ajouter un d√©lai plus long entre les mises √† jour pour √©viter les probl√®mes de quota
            print("   üìä Mise √† jour des feuilles d√©taill√©es...")
            
            self._update_company_size_sheet(stats)
            print("   ‚è≥ Attente de 10 secondes pour √©viter les quotas...")
            time.sleep(10)
            
            self._update_seniority_sheet(stats)
            print("   ‚è≥ Attente de 10 secondes pour √©viter les quotas...")
            time.sleep(10)
            
            self._update_function_sheet(stats)
            print("   ‚è≥ Attente de 10 secondes pour √©viter les quotas...")
            time.sleep(10)
            
            self._update_industry_sheet(stats)
            
        except Exception as e:
            print(f"   Erreur lors de la mise √† jour des feuilles d√©taill√©es: {e}")
    
    def _update_company_size_sheet(self, stats):
        """Met √† jour la feuille des statistiques par taille d'entreprise avec formatage optimis√©"""
        try:
            print("   üè¢ Mise √† jour de la feuille 'Par Taille'...")
            
            # V√©rifier si la feuille existe d√©j√†
            try:
                sheet = self.spreadsheet.worksheet("Par Taille")
            except gspread.exceptions.WorksheetNotFound:
                sheet = safe_sheets_operation(self.spreadsheet.add_worksheet, title="Par Taille", rows=100, cols=5)
                print("   Nouvelle feuille 'Par Taille' cr√©√©e")
            
            # Nettoyer la feuille
            safe_sheets_operation(sheet.clear)
            time.sleep(2)
            
            # Pr√©parer les donn√©es SANS la colonne Date
            data = []
            data.append(['Taille_Max_Employ√©s', 'Description', 'Followers_Organiques', 'Followers_Payants', 'Total_Followers'])
            
            size_entries = []
            
            for size, values in stats['by_company_size'].items():
                organic = values['organic']
                paid = values['paid']
                total = values['total']
                numeric_size = values.get('numeric_size', 0)
                size_entries.append((numeric_size, size, organic, paid, total))
            
            # Trier par taille (ordre croissant)
            size_entries.sort(key=lambda x: x[0])
            
            # Ajouter √† la liste de donn√©es SANS date
            for numeric_size, size_name, organic, paid, total in size_entries:
                data.append([numeric_size, size_name, organic, paid, total])
            
            # Mettre √† jour la feuille avec les donn√©es
            if data:
                safe_sheets_operation(sheet.update, data, 'A1')
                time.sleep(1)
            
            # FORMATAGE OPTIMIS√â POUR LOOKER STUDIO
            # Formater les en-t√™tes
            safe_sheets_operation(sheet.format, 'A1:E1', {
                "textFormat": {"bold": True},
                "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9}
            })
            time.sleep(1)
            
            # Formater la colonne Taille_Max_Employ√©s (A) comme NUMBER
            safe_sheets_operation(sheet.format, 'A2:A' + str(len(data)), {
                "numberFormat": {"type": "NUMBER", "pattern": "#,##0"}
            })
            time.sleep(1)
            
            # Formater les colonnes de followers (C, D, E) comme NUMBER
            safe_sheets_operation(sheet.format, 'C2:E' + str(len(data)), {
                "numberFormat": {"type": "NUMBER", "pattern": "#,##0"}
            })
            
        except Exception as e:
            print(f"   Erreur lors de la mise √† jour de la feuille des tailles d'entreprise: {e}")
    
    def _update_seniority_sheet(self, stats):
        """Met √† jour la feuille des statistiques par s√©niorit√© avec formatage optimis√©"""
        try:
            print("   üëî Mise √† jour de la feuille 'Par S√©niorit√©'...")
            
            # V√©rifier si la feuille existe d√©j√†
            try:
                sheet = self.spreadsheet.worksheet("Par S√©niorit√©")
            except gspread.exceptions.WorksheetNotFound:
                sheet = safe_sheets_operation(self.spreadsheet.add_worksheet, title="Par S√©niorit√©", rows=100, cols=5)
                print("   Nouvelle feuille 'Par S√©niorit√©' cr√©√©e")
            
            # Nettoyer la feuille
            safe_sheets_operation(sheet.clear)
            time.sleep(2)
            
            # Pr√©parer les donn√©es SANS la colonne Date
            data = []
            data.append(['Niveau_S√©niorit√©', 'Description', 'Followers_Organiques', 'Followers_Payants', 'Total_Followers'])
            
            seniority_entries = []
            
            for seniority_id, values in stats['by_seniority'].items():
                seniority_name = values.get('name', f"Niveau {seniority_id}")
                organic = values['organic']
                paid = values['paid']
                total = values['total']
                
                # Essayer de convertir en nombre pour le tri
                try:
                    numeric_seniority = int(seniority_id)
                except ValueError:
                    numeric_seniority = 999  # Pour "Non sp√©cifi√©"
                
                seniority_entries.append((numeric_seniority, seniority_name, organic, paid, total))
            
            # Trier par niveau (ordre croissant)
            seniority_entries.sort(key=lambda x: x[0])
            
            # Ajouter √† la liste de donn√©es SANS date
            for level, description, organic, paid, total in seniority_entries:
                data.append([level, description, organic, paid, total])
            
            # Mettre √† jour la feuille avec les donn√©es
            if data:
                safe_sheets_operation(sheet.update, data, 'A1')
                time.sleep(1)
            
            # FORMATAGE OPTIMIS√â POUR LOOKER STUDIO
            # Formater les en-t√™tes
            safe_sheets_operation(sheet.format, 'A1:E1', {
                "textFormat": {"bold": True},
                "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9}
            })
            time.sleep(1)
            
            # Formater la colonne Niveau_S√©niorit√© (A) comme NUMBER
            safe_sheets_operation(sheet.format, 'A2:A' + str(len(data)), {
                "numberFormat": {"type": "NUMBER", "pattern": "0"}
            })
            time.sleep(1)
            
            # Formater les colonnes de followers (C, D, E) comme NUMBER
            safe_sheets_operation(sheet.format, 'C2:E' + str(len(data)), {
                "numberFormat": {"type": "NUMBER", "pattern": "#,##0"}
            })
            
        except Exception as e:
            print(f"   Erreur lors de la mise √† jour de la feuille des s√©niorit√©s: {e}")
            
    def _update_function_sheet(self, stats):
        """Met √† jour la feuille des statistiques par fonction avec formatage optimis√©"""
        try:
            print("   üíº Mise √† jour de la feuille 'Par Fonction'...")
            
            # V√©rifier si la feuille existe d√©j√†
            try:
                sheet = self.spreadsheet.worksheet("Par Fonction")
            except gspread.exceptions.WorksheetNotFound:
                sheet = safe_sheets_operation(self.spreadsheet.add_worksheet, title="Par Fonction", rows=100, cols=5)
                print("   Nouvelle feuille 'Par Fonction' cr√©√©e")
            
            # Nettoyer la feuille
            safe_sheets_operation(sheet.clear)
            time.sleep(2)
            
            # Pr√©parer les donn√©es SANS la colonne Date
            data = []
            data.append(['Fonction_ID', 'Nom_Fonction', 'Followers_Organiques', 'Followers_Payants', 'Total_Followers'])
            
            # Trier par nombre de followers (ordre d√©croissant)
            function_entries = []
            for function_id, values in stats['by_function'].items():
                function_name = values.get('name', f"Fonction {function_id}")
                organic = values['organic']
                paid = values['paid']
                total = values['total']
                
                # Convertir l'ID en nombre pour Looker
                try:
                    numeric_id = int(function_id)
                except ValueError:
                    numeric_id = 0  # Pour "Non sp√©cifi√©"
                
                function_entries.append((numeric_id, function_name, organic, paid, total))
                
            # Trier par nombre de followers d√©croissant
            function_entries.sort(key=lambda x: x[4], reverse=True)
            
            # Ajouter √† la liste de donn√©es SANS date
            for function_id, function_name, organic, paid, total in function_entries:
                data.append([function_id, function_name, organic, paid, total])
            
            # Mettre √† jour la feuille avec les donn√©es
            if data:
                safe_sheets_operation(sheet.update, data, 'A1')
                time.sleep(1)
            
            # FORMATAGE OPTIMIS√â POUR LOOKER STUDIO
            # Formater les en-t√™tes
            safe_sheets_operation(sheet.format, 'A1:E1', {
                "textFormat": {"bold": True},
                "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9}
            })
            time.sleep(1)
            
            # Formater la colonne Fonction_ID (A) comme NUMBER
            safe_sheets_operation(sheet.format, 'A2:A' + str(len(data)), {
                "numberFormat": {"type": "NUMBER", "pattern": "0"}
            })
            time.sleep(1)
            
            # Formater les colonnes de followers (C, D, E) comme NUMBER
            safe_sheets_operation(sheet.format, 'C2:E' + str(len(data)), {
                "numberFormat": {"type": "NUMBER", "pattern": "#,##0"}
            })
            
        except Exception as e:
            print(f"   Erreur lors de la mise √† jour de la feuille des fonctions: {e}")
    
    def _update_industry_sheet(self, stats):
        """Met √† jour la feuille des statistiques par industrie avec formatage optimis√©"""
        try:
            print("   üè≠ Mise √† jour de la feuille 'Par Industrie'...")
            
            # V√©rifier si la feuille existe d√©j√†
            try:
                sheet = self.spreadsheet.worksheet("Par Industrie")
            except gspread.exceptions.WorksheetNotFound:
                sheet = safe_sheets_operation(self.spreadsheet.add_worksheet, title="Par Industrie", rows=1000, cols=5)
                print("   Nouvelle feuille 'Par Industrie' cr√©√©e")
            
            # Nettoyer la feuille
            safe_sheets_operation(sheet.clear)
            time.sleep(2)
            
            # Pr√©parer les donn√©es SANS la colonne Date
            data = []
            data.append(['Industrie_ID', 'Nom_Industrie', 'Followers_Organiques', 'Followers_Payants', 'Total_Followers'])
            
            # Trier par nombre de followers (ordre d√©croissant)
            industry_entries = []
            for industry_id, values in stats['by_industry'].items():
                industry_name = values.get('name', f"Industrie {industry_id}")
                organic = values['organic']
                paid = values['paid']
                total = values['total']
                
                # Convertir l'ID en nombre pour Looker
                try:
                    numeric_id = int(industry_id)
                except ValueError:
                    numeric_id = 0  # Pour "Non sp√©cifi√©"
                
                industry_entries.append((numeric_id, industry_name, organic, paid, total))
                
            # Trier par nombre de followers d√©croissant
            industry_entries.sort(key=lambda x: x[4], reverse=True)
            
            # Ajouter √† la liste de donn√©es SANS date
            for industry_id, industry_name, organic, paid, total in industry_entries:
                data.append([industry_id, industry_name, organic, paid, total])
            
            # Mettre √† jour la feuille avec les donn√©es
            if data:
                safe_sheets_operation(sheet.update, data, 'A1')
                time.sleep(1)
            
            # FORMATAGE OPTIMIS√â POUR LOOKER STUDIO
            # Formater les en-t√™tes
            safe_sheets_operation(sheet.format, 'A1:E1', {
                "textFormat": {"bold": True},
                "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9}
            })
            time.sleep(1)
            
            # Formater la colonne Industrie_ID (A) comme NUMBER
            safe_sheets_operation(sheet.format, 'A2:A' + str(len(data)), {
                "numberFormat": {"type": "NUMBER", "pattern": "0"}
            })
            time.sleep(1)
            
            # Formater les colonnes de followers (C, D, E) comme NUMBER
            safe_sheets_operation(sheet.format, 'C2:E' + str(len(data)), {
                "numberFormat": {"type": "NUMBER", "pattern": "#,##0"}
            })
            
        except Exception as e:
            print(f"   Erreur lors de la mise √† jour de la feuille des industries: {e}")
    
    def add_follower_statistics(self, stats):
        """Ajoute les statistiques de followers"""
        if not self.connect():
            print("   Impossible de se connecter √† Google Sheets. V√©rifiez vos credentials.")
            return False
            
        # V√©rifier les permissions de partage pour s'assurer que l'admin a toujours acc√®s
        self.ensure_admin_access()
        
        # Attendre un peu avant de commencer les mises √† jour
        time.sleep(2)
        
        # Mettre √† jour les feuilles
        summary_sheet = self.prepare_and_update_summary_sheet(stats)
        if summary_sheet:
            print("   ‚úÖ Feuille de r√©sum√© mise √† jour avec succ√®s")
            # Attendre avant de passer aux feuilles d√©taill√©es
            print("   ‚è≥ Attente de 5 secondes avant les feuilles d√©taill√©es...")
            time.sleep(5)
            
            self.prepare_and_update_detail_sheets(stats)
        else:
            print("   ‚ùå √âchec de la mise √† jour de la feuille de r√©sum√©")
            return False
        
        # URL du spreadsheet
        sheet_url = f"https://docs.google.com/spreadsheets/d/{self.spreadsheet.id}"
        print(f"   URL du tableau: {sheet_url}")
        
        return True


def verify_token(access_token):
    """V√©rifie si le token d'acc√®s est valide"""
    headers = {
        "Authorization": f"Bearer {access_token}",
        "X-Restli-Protocol-Version": "2.0.0",
        "LinkedIn-Version": "202505"
    }
    
    url = "https://api.linkedin.com/rest/me"
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            return True, response.json()
        else:
            return False, f"Erreur {response.status_code}: {response.text}"
    except Exception as e:
        return False, str(e)


class MultiOrganizationFollowerStatsTracker:
    """Gestionnaire pour les statistiques de followers de plusieurs organisations LinkedIn"""
    
    def __init__(self, config_file='organizations_config.json'):
        """Initialise le tracker multi-organisations"""
        self.config_file = config_file
        self.organizations = self.load_organizations()
        self.access_token = os.getenv("LINKEDIN_ACCESS_TOKEN", "").strip("'")
        self.admin_email = os.getenv("GOOGLE_ADMIN_EMAIL", "byteberry.analytics@gmail.com")
        self.follower_stats_mapping_file = 'follower_stats_mapping.json'
        
    def load_organizations(self):
        """Charge la configuration des organisations depuis un fichier JSON"""
        try:
            # D'abord essayer de charger depuis un fichier local
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            
            # Sinon, charger depuis une variable d'environnement
            orgs_json = os.getenv("LINKEDIN_ORGANIZATIONS_CONFIG")
            if orgs_json:
                return json.loads(orgs_json)
            
            # Configuration par d√©faut
            print("Aucune configuration trouv√©e, utilisation de la configuration par d√©faut")
            return []
            
        except Exception as e:
            print(f"Erreur lors du chargement de la configuration: {e}")
            return []
    
    def get_sheet_info_for_org(self, org_id, org_name):
        """R√©cup√®re ou cr√©e l'ID et le nom du Google Sheet pour une organisation"""
        try:
            if os.path.exists(self.follower_stats_mapping_file):
                with open(self.follower_stats_mapping_file, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
            else:
                mapping = {}
            
            # Si l'organisation a d√©j√† un sheet ID, le retourner
            if org_id in mapping:
                print(f"   üìÇ R√©utilisation du Google Sheet existant")
                return mapping[org_id]['sheet_id'], mapping[org_id]['sheet_name']
            
            # Sinon, utiliser le nom par d√©faut
            clean_name = org_name.replace(' ', '_').replace('‚Ñ¢', '').replace('/', '_')
            sheet_name = f"LinkedIn_Follower_Stats_{clean_name}_{org_id}"
            
            # Stocker le mapping pour la prochaine fois
            mapping[org_id] = {
                'sheet_name': sheet_name,
                'sheet_id': None,  # Sera mis √† jour apr√®s cr√©ation
                'org_name': org_name
            }
            
            with open(self.follower_stats_mapping_file, 'w', encoding='utf-8') as f:
                json.dump(mapping, f, indent=2, ensure_ascii=False)
            
            return None, sheet_name
            
        except Exception as e:
            print(f"Erreur dans la gestion du mapping: {e}")
            clean_name = org_name.replace(' ', '_').replace('‚Ñ¢', '').replace('/', '_')
            sheet_name = f"LinkedIn_Follower_Stats_{clean_name}_{org_id}"
            return None, sheet_name
    
    def update_sheet_mapping(self, org_id, sheet_id):
        """Met √† jour le mapping avec l'ID du sheet cr√©√©"""
        try:
            if os.path.exists(self.follower_stats_mapping_file):
                with open(self.follower_stats_mapping_file, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
            else:
                mapping = {}
            
            if org_id in mapping:
                mapping[org_id]['sheet_id'] = sheet_id
                mapping[org_id]['sheet_url'] = f"https://docs.google.com/spreadsheets/d/{sheet_id}"
                
                with open(self.follower_stats_mapping_file, 'w', encoding='utf-8') as f:
                    json.dump(mapping, f, indent=2, ensure_ascii=False)
                    
        except Exception as e:
            print(f"Erreur lors de la mise √† jour du mapping: {e}")
    
    def process_all_organizations(self):
        """Traite toutes les organisations configur√©es"""
        if not self.access_token:
            print("Erreur: LINKEDIN_ACCESS_TOKEN manquant")
            return False
        
        # V√©rifier le token une seule fois
        print("\n--- V√©rification du token ---")
        is_valid, result = verify_token(self.access_token)
        
        if not is_valid:
            print(f"‚ùå Token invalide: {result}")
            return False
        
        print("‚úÖ Token valide!")
        user_info = result
        print(f"   Utilisateur: {user_info.get('localizedFirstName', '')} {user_info.get('localizedLastName', '')}")
        
        # Traiter chaque organisation
        results = []
        total_orgs = len(self.organizations)
        successful_urls = []
        
        for idx, org in enumerate(self.organizations, 1):
            org_id = org['id']
            org_name = org['name']
            
            print(f"\n{'='*60}")
            print(f"[{idx}/{total_orgs}] Traitement de: {org_name}")
            print(f"ID: {org_id}")
            print(f"{'='*60}")
            
            try:
                sheet_url = self.process_single_organization(org_id, org_name)
                if sheet_url:
                    results.append({
                        'org_id': org_id,
                        'org_name': org_name,
                        'success': True,
                        'sheet_url': sheet_url,
                        'timestamp': datetime.now().isoformat()
                    })
                    successful_urls.append({
                        'name': org_name,
                        'url': sheet_url
                    })
                else:
                    results.append({
                        'org_id': org_id,
                        'org_name': org_name,
                        'success': False,
                        'timestamp': datetime.now().isoformat()
                    })
                    
                # Attendre entre chaque organisation pour √©viter les probl√®mes de quota
                if idx < total_orgs:  # Ne pas attendre apr√®s la derni√®re organisation
                    print(f"   ‚è≥ Attente de 15 secondes avant la prochaine organisation...")
                    time.sleep(15)
                    
            except Exception as e:
                print(f"‚ùå Erreur lors du traitement de {org_name}: {e}")
                results.append({
                    'org_id': org_id,
                    'org_name': org_name,
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
        
        # R√©sum√©
        print(f"\n{'='*60}")
        print("R√âSUM√â DU TRAITEMENT - STATISTIQUES DE FOLLOWERS")
        print(f"{'='*60}")
        
        successful = sum(1 for r in results if r['success'])
        failed = len(results) - successful
        
        print(f"‚úÖ Organisations trait√©es avec succ√®s: {successful}/{total_orgs}")
        if failed > 0:
            print(f"‚ùå Organisations en √©chec: {failed}/{total_orgs}")
        
        if failed > 0:
            print("\nD√©tail des √©checs:")
            for r in results:
                if not r['success']:
                    error_msg = r.get('error', 'Erreur inconnue')
                    print(f"  - {r['org_name']}: {error_msg}")
        
        # Afficher les URLs des sheets cr√©√©s
        if successful > 0:
            print("\nüìä Google Sheets de statistiques de followers cr√©√©s/mis √† jour:")
            if os.path.exists(self.follower_stats_mapping_file):
                with open(self.follower_stats_mapping_file, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
                
                for r in results:
                    if r['success'] and r['org_id'] in mapping:
                        sheet_info = mapping[r['org_id']]
                        if sheet_info.get('sheet_id'):
                            print(f"  - {r['org_name']}:")
                            url = sheet_info.get('sheet_url') or f"https://docs.google.com/spreadsheets/d/{sheet_info['sheet_id']}"
                            print(f"    {url}")
        
        return successful > 0
    
    def process_single_organization(self, org_id, org_name):
        """Traite une organisation unique"""
        # Obtenir le nom du sheet pour cette organisation
        sheet_id, sheet_name = self.get_sheet_info_for_org(org_id, org_name)
        
        print(f"\nüìä Google Sheet: {sheet_name}")
        
        # Initialisation du tracker
        tracker = LinkedInFollowerStatisticsTracker(self.access_token, org_id, sheet_name)
        
        # Obtention des statistiques
        print("\n1. R√©cup√©ration des statistiques de followers...")
        raw_stats = tracker.get_follower_statistics()
        
        if raw_stats:
            # Traitement des donn√©es
            print("\n2. Analyse des donn√©es statistiques...")
            stats = tracker.parse_follower_statistics(raw_stats)
            
            # Afficher un aper√ßu
            print("\nüìà Aper√ßu des statistiques:")
            print(f"   Total followers (r√©el): {stats.get('total_followers', 0)}")
            print(f"   Tailles d'entreprises repr√©sent√©es: {len(stats.get('by_company_size', {}))}")
            print(f"   Fonctions repr√©sent√©es: {len(stats.get('by_function', {}))}")
            print(f"   Niveaux de s√©niorit√©: {len(stats.get('by_seniority', {}))}")
            print(f"   Industries repr√©sent√©es: {len(stats.get('by_industry', {}))}")
            
            # Afficher les followers non cat√©goris√©s
            print("\nüìä R√©partition des followers non cat√©goris√©s:")
            for category, data in [('by_company_size', 'Taille'), ('by_function', 'Fonction'), 
                                 ('by_seniority', 'S√©niorit√©'), ('by_industry', 'Industrie')]:
                if category in stats:
                    for key, values in stats[category].items():
                        if 'Non sp√©cifi√©' in values.get('name', key):
                            print(f"   {data}: {values['total']} followers non sp√©cifi√©s")
            
            # Chemin vers les credentials
            if os.getenv('K_SERVICE'):  # Cloud Run/Functions
                credentials_path = Path('/tmp/credentials/service_account_credentials.json')
            else:  # Local
                credentials_path = Path(__file__).resolve().parent / 'credentials' / 'service_account_credentials.json'
            
            if not credentials_path.exists():
                # Essayer de cr√©er les credentials depuis une variable d'environnement
                creds_json = os.getenv('GOOGLE_SERVICE_ACCOUNT_JSON')
                if creds_json:
                    # √âviter de cr√©er des dossiers dans /app
                    if not str(credentials_path).startswith('/app'):
                        credentials_path.parent.mkdir(parents=True, exist_ok=True)
                    with open(credentials_path, 'w') as f:
                        f.write(creds_json)
                    print("   ‚úÖ Credentials cr√©√©s depuis la variable d'environnement")
                else:
                    print(f"   ‚ùå Erreur: Fichier de credentials non trouv√©: {credentials_path}")
                    return None
            else:
                print("   ‚úÖ Credentials trouv√©s")
            
            # Export vers Google Sheets
            print("\n3. Export vers Google Sheets...")
            exporter = GoogleSheetsExporter(tracker.sheet_name, credentials_path, self.admin_email)
            success = exporter.add_follower_statistics(stats)
            
            if success and exporter.spreadsheet:
                # Mettre √† jour le mapping avec l'ID du sheet
                self.update_sheet_mapping(org_id, exporter.spreadsheet.id)
                sheet_url = f"https://docs.google.com/spreadsheets/d/{exporter.spreadsheet.id}"
                print(f"\n‚úÖ Export r√©ussi pour {org_name}!")
                print(f"üìä URL du Sheet: {sheet_url}")
                return sheet_url
            else:
                print(f"\n‚ùå √âchec de l'export pour {org_name}")
                return None
        else:
            print("   ‚ùå Impossible de r√©cup√©rer les statistiques de followers")
            return None


def main():
    """Fonction principale"""
    print("="*60)
    print("LINKEDIN MULTI-ORGANISATION FOLLOWER STATISTICS TRACKER")
    print("="*60)
    print(f"Date d'ex√©cution: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Cr√©er le tracker
    tracker = MultiOrganizationFollowerStatsTracker()
    
    if not tracker.organizations:
        print("\n‚ùå Aucune organisation configur√©e!")
        print("\nPour configurer des organisations:")
        print("1. Lancez d'abord: python3 discover_organizations.py")
        print("2. Ou cr√©ez manuellement 'organizations_config.json' avec le format:")
        print(json.dumps([
            {"id": "123456", "name": "Entreprise A"},
            {"id": "789012", "name": "Entreprise B"}
        ], indent=2))
        sys.exit(1)
    
    print(f"\nüìã Organisations configur√©es: {len(tracker.organizations)}")
    for org in tracker.organizations:
        print(f"   - {org['name']} (ID: {org['id']})")
    
    print(f"\n‚öôÔ∏è  Configuration:")
    print(f"   - Email admin: {tracker.admin_email}")
    print(f"   - Type de donn√©es: Statistiques d√©taill√©es des followers")
    print(f"   - Formatage: Optimis√© pour Looker Studio")
    print(f"   - Gestion des followers non cat√©goris√©s: ‚úÖ Activ√©e")
    
    # Demander confirmation si plus de 5 organisations
    if len(tracker.organizations) > 5:
        print(f"\n‚ö†Ô∏è  Attention: {len(tracker.organizations)} organisations √† traiter.")
        print("   Cela peut prendre du temps et consommer des quotas API.")
        if os.getenv('AUTOMATED_MODE', 'false').lower() == 'true':
            response = 'o'
            print('ü§ñ Mode automatis√©: r√©ponse automatique \'o\'')
        else:
            response = input("   Continuer ? (o/N): ")
        if response.lower() != 'o':
            print("Annul√©.")
            sys.exit(0)
    
    print("\nüöÄ D√©marrage du traitement des statistiques de followers...")
    print("‚è≥ Note: Le traitement inclut des d√©lais pour respecter les quotas Google Sheets")
    
    # Lancer le traitement
    start_time = datetime.now()
    success = tracker.process_all_organizations()
    end_time = datetime.now()
    
    # Afficher le temps d'ex√©cution
    duration = end_time - start_time
    minutes = int(duration.total_seconds() // 60)
    seconds = int(duration.total_seconds() % 60)
    
    print(f"\n‚è±Ô∏è  Temps d'ex√©cution: {minutes}m {seconds}s")
    
    if success:
        print("\nüìä Les Google Sheets sont maintenant optimis√©s pour Looker Studio avec:")
        print("   ‚úÖ Formatage des dates (DATE) - uniquement dans l'onglet R√©sum√©")
        print("   ‚úÖ Formatage des nombres (NUMBER)")
        print("   ‚úÖ Formatage des pourcentages (PERCENT)")
        print("   ‚úÖ Noms de colonnes sans espaces ni caract√®res sp√©ciaux")
        print("   ‚úÖ Types de donn√©es coh√©rents pour chaque colonne")
        print("   ‚úÖ Cat√©gorie 'Non sp√©cifi√©' pour les followers non cat√©goris√©s")
        print("   ‚úÖ Total de followers r√©el bas√© sur l'API networkSizes")
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()