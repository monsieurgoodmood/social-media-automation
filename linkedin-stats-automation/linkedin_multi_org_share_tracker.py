#!/usr/bin/env python3
"""
LinkedIn Multi-Organization Share Statistics Tracker
Ce script collecte les statistiques de partage pour plusieurs organisations LinkedIn
et les enregistre dans Google Sheets avec un formatage optimis√© pour Looker Studio.
"""

import os
import json
import requests
import urllib.parse
from pathlib import Path
from datetime import datetime
import time
import sys
from dotenv import load_dotenv
import random

# Pour Google Sheets
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from gspread.exceptions import APIError

# Chargement des variables d'environnement
load_dotenv()

def safe_sheets_operation(operation, *args, max_retries=5, **kwargs):
    """
    Ex√©cute une op√©ration Google Sheets avec gestion des erreurs de quota et de service
    """
    for attempt in range(max_retries):
        try:
            return operation(*args, **kwargs)
        except APIError as e:
            error_code = str(e)
            
            # Gestion des diff√©rents types d'erreurs
            if '429' in error_code or 'Quota exceeded' in error_code:
                # Quota d√©pass√©
                base_delay = min(60, (2 ** attempt) * 5)
                jitter = random.uniform(0.5, 1.5)
                delay = base_delay * jitter
                print(f"   ‚è≥ Quota d√©pass√© (tentative {attempt + 1}/{max_retries}), attente de {delay:.1f}s...")
                time.sleep(delay)
            elif '503' in error_code or 'unavailable' in error_code.lower():
                # Service indisponible
                base_delay = min(120, (2 ** attempt) * 10)
                jitter = random.uniform(0.8, 1.2)
                delay = base_delay * jitter
                print(f"   üîÑ Service Google Sheets indisponible (tentative {attempt + 1}/{max_retries}), attente de {delay:.1f}s...")
                time.sleep(delay)
            elif '500' in error_code or '502' in error_code or '504' in error_code:
                # Erreurs serveur
                base_delay = min(60, (2 ** attempt) * 8)
                jitter = random.uniform(0.7, 1.3)
                delay = base_delay * jitter
                print(f"   üîß Erreur serveur Google (tentative {attempt + 1}/{max_retries}), attente de {delay:.1f}s...")
                time.sleep(delay)
            elif '400' in error_code and 'exceeds grid limits' in error_code:
                # Erreur de limites de grille
                print(f"   ‚ö†Ô∏è Erreur de limites de grille: {e}")
                print(f"   üîß Tentative d'ignorer cette op√©ration de formatage...")
                return None  # Ignorer cette op√©ration
            else:
                print(f"   ‚ùå Erreur API non g√©r√©e: {e}")
                if attempt == max_retries - 1:
                    raise
                time.sleep(5)
                
            if attempt == max_retries - 1:
                print(f"   ‚ùå √âchec apr√®s {max_retries} tentatives: {e}")
                raise
                
        except Exception as e:
            print(f"   ‚ùå Erreur inattendue: {e}")
            if attempt == max_retries - 1:
                raise
            # Attendre un peu avant de r√©essayer
            time.sleep(min(30, (2 ** attempt) * 2))

class LinkedInShareStatisticsTracker:
    """Classe pour suivre les statistiques des partages LinkedIn d'une organisation"""
    
    def __init__(self, access_token, organization_id, sheet_name=None):
        """Initialise le tracker avec le token d'acc√®s et l'ID de l'organisation"""
        self.access_token = access_token
        self.organization_id = organization_id
        self.sheet_name = sheet_name or f"LinkedIn_Share_Stats_{organization_id}"
        self.base_url = "https://api.linkedin.com/v2"
        
    def get_headers(self):
        """Retourne les en-t√™tes pour les requ√™tes API"""
        return {
            "Authorization": f"Bearer {self.access_token}",
            "X-Restli-Protocol-Version": "2.0.0",
            "LinkedIn-Version": "202312",
            "Content-Type": "application/json"
        }
    
    def get_share_statistics(self):
        """Obtient les statistiques de partage pour l'organisation"""
        # Encoder l'URN de l'organisation
        organization_urn = f"urn:li:organization:{self.organization_id}"
        encoded_urn = urllib.parse.quote(organization_urn)
        
        # Construire l'URL
        url = f"{self.base_url}/organizationalEntityShareStatistics?q=organizationalEntity&organizationalEntity={encoded_urn}"
        
        # Effectuer la requ√™te avec gestion des erreurs et retry
        max_retries = 3
        retry_delay = 2  # secondes
        
        for attempt in range(max_retries):
            try:
                response = requests.get(url, headers=self.get_headers())
                
                if response.status_code == 200:
                    data = response.json()
                    print(f"   Donn√©es de statistiques de partage r√©cup√©r√©es avec succ√®s")
                    return data
                    
                elif response.status_code == 429:
                    # Rate limit, attendre avant de r√©essayer
                    print(f"   Rate limit atteint, attente de {retry_delay} secondes...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Backoff exponentiel
                else:
                    print(f"   Erreur API: {response.status_code} - {response.text}")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    
            except Exception as e:
                print(f"   Exception lors de la requ√™te: {e}")
                time.sleep(retry_delay)
                retry_delay *= 2
        
        print("   √âchec apr√®s plusieurs tentatives pour obtenir les statistiques de partage.")
        return None
    
    def get_page_statistics(self):
        """Obtient les statistiques de la page pour l'organisation (m√©triques lifetime)"""
        # Encoder l'URN de l'organisation
        organization_urn = f"urn:li:organization:{self.organization_id}"
        encoded_urn = urllib.parse.quote(organization_urn)
        
        # Construire l'URL
        url = f"{self.base_url}/organizationPageStatistics?q=organization&organization={encoded_urn}"
        
        # Effectuer la requ√™te avec gestion des erreurs et retry
        max_retries = 3
        retry_delay = 2  # secondes
        
        for attempt in range(max_retries):
            try:
                response = requests.get(url, headers=self.get_headers())
                
                if response.status_code == 200:
                    data = response.json()
                    print(f"   Donn√©es de statistiques lifetime de la page r√©cup√©r√©es avec succ√®s")
                    return data
                    
                elif response.status_code == 429:
                    # Rate limit, attendre avant de r√©essayer
                    print(f"   Rate limit atteint, attente de {retry_delay} secondes...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Backoff exponentiel
                else:
                    print(f"   Erreur API: {response.status_code} - {response.text}")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    
            except Exception as e:
                print(f"   Exception lors de la requ√™te: {e}")
                time.sleep(retry_delay)
                retry_delay *= 2
        
        print("   √âchec apr√®s plusieurs tentatives pour obtenir les statistiques lifetime de la page.")
        return None
    
    def parse_share_statistics(self, share_data, page_data=None):
        """Analyse les donn√©es de l'API et extrait les statistiques pertinentes"""
        stats = {}
        
        # Date de r√©cup√©ration (en string pour √©viter les erreurs de s√©rialisation)
        stats['date'] = datetime.now().strftime('%Y-%m-%d')
        
        # S'assurer que les donn√©es de partage sont valides
        if not share_data or 'elements' not in share_data or len(share_data['elements']) == 0:
            print("   Aucune donn√©e de statistiques de partage valide trouv√©e.")
            # Initialiser avec des valeurs par d√©faut
            stats['impressions'] = {'total': 0, 'unique': 0}
            stats['engagement'] = {
                'rate': 0,
                'clicks': 0,
                'likes': 0,
                'comments': 0,
                'shares': 0,
                'share_mentions': 0,
                'comment_mentions': 0,
                'total_interactions': 0,
                'click_through_rate': 0,
                'interaction_rate': 0
            }
        else:
            # Obtenir le premier √©l√©ment (qui contient les stats d'organisation)
            element = share_data['elements'][0]
            
            if 'totalShareStatistics' not in element:
                print("   Aucune statistique de partage trouv√©e dans les donn√©es.")
                # Initialiser avec des valeurs par d√©faut
                stats['impressions'] = {'total': 0, 'unique': 0}
                stats['engagement'] = {
                    'rate': 0,
                    'clicks': 0,
                    'likes': 0,
                    'comments': 0,
                    'shares': 0,
                    'share_mentions': 0,
                    'comment_mentions': 0,
                    'total_interactions': 0,
                    'click_through_rate': 0,
                    'interaction_rate': 0
                }
            else:
                # Extraire les statistiques principales
                share_stats = element['totalShareStatistics']
                
                stats['impressions'] = {
                    'total': share_stats.get('impressionCount', 0),
                    'unique': share_stats.get('uniqueImpressionsCount', 0)
                }
                
                stats['engagement'] = {
                    'rate': share_stats.get('engagement', 0),  # Garder en d√©cimal pour Looker
                    'clicks': share_stats.get('clickCount', 0),
                    'likes': share_stats.get('likeCount', 0),
                    'comments': share_stats.get('commentCount', 0),
                    'shares': share_stats.get('shareCount', 0),
                    'share_mentions': share_stats.get('shareMentionsCount', 0),
                    'comment_mentions': share_stats.get('commentMentionsCount', 0)
                }
                
                # Calcul de m√©triques d√©riv√©es
                if stats['impressions']['total'] > 0:
                    stats['engagement']['click_through_rate'] = (stats['engagement']['clicks'] / stats['impressions']['total'])  # D√©cimal
                else:
                    stats['engagement']['click_through_rate'] = 0
                    
                # Calculer le nombre total d'interactions
                total_interactions = (
                    stats['engagement']['clicks'] +
                    stats['engagement']['likes'] +
                    stats['engagement']['comments'] +
                    stats['engagement']['shares']
                )
                
                stats['engagement']['total_interactions'] = total_interactions
                
                if stats['impressions']['total'] > 0:
                    stats['engagement']['interaction_rate'] = (total_interactions / stats['impressions']['total'])  # D√©cimal
                else:
                    stats['engagement']['interaction_rate'] = 0
        
        # Ajout des statistiques lifetime de la page si disponibles
        stats['page_lifetime'] = {}
        
        if page_data and 'elements' in page_data and len(page_data['elements']) > 0:
            element = page_data['elements'][0]
            
            if 'totalPageStatistics' in element:
                total_stats = element['totalPageStatistics']
                
                # Statistiques de vues
                if 'views' in total_stats:
                    views = total_stats['views']
                    stats['page_lifetime']['views'] = {
                        'all_page_views': views.get('allPageViews', {}).get('pageViews', 0),
                        'desktop_page_views': views.get('allDesktopPageViews', {}).get('pageViews', 0),
                        'mobile_page_views': views.get('allMobilePageViews', {}).get('pageViews', 0),
                        
                        # Vues par section
                        'overview_page_views': views.get('overviewPageViews', {}).get('pageViews', 0),
                        'about_page_views': views.get('aboutPageViews', {}).get('pageViews', 0) if 'aboutPageViews' in views else 0,
                        'people_page_views': views.get('peoplePageViews', {}).get('pageViews', 0) if 'peoplePageViews' in views else 0,
                        'jobs_page_views': views.get('jobsPageViews', {}).get('pageViews', 0) if 'jobsPageViews' in views else 0,
                        'careers_page_views': views.get('careersPageViews', {}).get('pageViews', 0) if 'careersPageViews' in views else 0,
                        'life_at_page_views': views.get('lifeAtPageViews', {}).get('pageViews', 0) if 'lifeAtPageViews' in views else 0,
                        
                        # Desktop par section
                        'desktop_overview_views': views.get('desktopOverviewPageViews', {}).get('pageViews', 0) if 'desktopOverviewPageViews' in views else 0,
                        'desktop_careers_views': views.get('desktopCareersPageViews', {}).get('pageViews', 0) if 'desktopCareersPageViews' in views else 0,
                        'desktop_jobs_views': views.get('desktopJobsPageViews', {}).get('pageViews', 0) if 'desktopJobsPageViews' in views else 0,
                        'desktop_life_at_views': views.get('desktopLifeAtPageViews', {}).get('pageViews', 0) if 'desktopLifeAtPageViews' in views else 0,
                        
                        # Mobile par section
                        'mobile_overview_views': views.get('mobileOverviewPageViews', {}).get('pageViews', 0) if 'mobileOverviewPageViews' in views else 0,
                        'mobile_careers_views': views.get('mobileCareersPageViews', {}).get('pageViews', 0) if 'mobileCareersPageViews' in views else 0,
                        'mobile_jobs_views': views.get('mobileJobsPageViews', {}).get('pageViews', 0) if 'mobileJobsPageViews' in views else 0,
                        'mobile_life_at_views': views.get('mobileLifeAtPageViews', {}).get('pageViews', 0) if 'mobileLifeAtPageViews' in views else 0
                    }
                
                # Statistiques de clics sur boutons
                if 'clicks' in total_stats:
                    clicks = total_stats['clicks']
                    
                    # Extraire les clics sur les boutons personnalis√©s
                    desktop_custom_button_clicks = clicks.get('desktopCustomButtonClickCounts', [])
                    mobile_custom_button_clicks = clicks.get('mobileCustomButtonClickCounts', [])
                    
                    # Calculer le total des clics sur les boutons personnalis√©s
                    desktop_button_clicks_total = sum([click.get('count', 0) for click in desktop_custom_button_clicks]) if desktop_custom_button_clicks else 0
                    mobile_button_clicks_total = sum([click.get('count', 0) for click in mobile_custom_button_clicks]) if mobile_custom_button_clicks else 0
                    
                    stats['page_lifetime']['clicks'] = {
                        'desktop_button_clicks': desktop_button_clicks_total,
                        'mobile_button_clicks': mobile_button_clicks_total,
                        'total_button_clicks': desktop_button_clicks_total + mobile_button_clicks_total
                    }
        
        return stats


class GoogleSheetsExporter:
    """Classe pour exporter les donn√©es vers Google Sheets avec formatage optimis√© pour Looker Studio"""
    
    def __init__(self, spreadsheet_name, credentials_path, admin_email="byteberry.analytics@gmail.com"):
        """Initialise l'exportateur avec le nom du spreadsheet et le chemin des credentials"""
        self.spreadsheet_name = spreadsheet_name
        self.credentials_path = credentials_path
        self.admin_email = admin_email
        self.client = None
        self.spreadsheet = None
        
    def connect(self):
        """√âtablit la connexion avec Google Sheets API"""
        try:
            scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
            creds = ServiceAccountCredentials.from_json_keyfile_name(str(self.credentials_path), scope)
            self.client = gspread.authorize(creds)
            
            # V√©rifier si le spreadsheet existe d√©j√†, sinon le cr√©er
            try:
                self.spreadsheet = self.client.open(self.spreadsheet_name)
                print(f"   Spreadsheet existant trouv√©: {self.spreadsheet_name}")
            except gspread.exceptions.SpreadsheetNotFound:
                self.spreadsheet = safe_sheets_operation(self.client.create, self.spreadsheet_name)
                print(f"   Nouveau spreadsheet cr√©√©: {self.spreadsheet_name}")
                
                # Donner l'acc√®s en √©dition √† l'adresse e-mail sp√©cifi√©e
                safe_sheets_operation(self.spreadsheet.share, self.admin_email, perm_type="user", role="writer")
                print(f"   Acc√®s en √©dition accord√© √† {self.admin_email}")
            
            return True
        except Exception as e:
            print(f"   Erreur de connexion √† Google Sheets: {e}")
            return False
    
    def ensure_admin_access(self):
        """V√©rifie et garantit que l'admin a toujours acc√®s au document"""
        try:
            # R√©cup√©rer les permissions actuelles
            permissions = safe_sheets_operation(self.spreadsheet.list_permissions)
            
            # V√©rifier si l'email admin est d√©j√† dans les permissions
            admin_has_access = False
            for permission in permissions:
                if 'emailAddress' in permission and permission['emailAddress'] == self.admin_email:
                    admin_has_access = True
                    # V√©rifier si le r√¥le est au moins "writer"
                    if permission.get('role') not in ['writer', 'owner']:
                        # Mettre √† jour le r√¥le si n√©cessaire
                        safe_sheets_operation(self.spreadsheet.share, self.admin_email, perm_type="user", role="writer")
                        print(f"   R√¥le mis √† jour pour {self.admin_email} (writer)")
                    break
            
            # Si l'admin n'a pas encore acc√®s, lui donner
            if not admin_has_access:
                safe_sheets_operation(self.spreadsheet.share, self.admin_email, perm_type="user", role="writer")
                print(f"   Acc√®s en √©dition accord√© √† {self.admin_email}")
                
        except Exception as e:
            print(f"   Erreur lors de la v√©rification des permissions: {e}")
    
    def update_stats_sheet(self, stats):
        """Met √† jour la feuille des statistiques avec UNE SEULE LIGNE (donn√©es lifetime)"""
        try:
            # D√©finir les en-t√™tes optimis√©s pour Looker (sans espaces, caract√®res sp√©ciaux)
            headers = [
                # Informations g√©n√©rales
                "Date_Mesure", 
                
                # Statistiques de partage (donn√©es cumulatives)
                "Impressions_Totales", 
                "Impressions_Uniques", 
                "Taux_Engagement", 
                "Clics_Totaux", 
                "Likes_Totaux", 
                "Commentaires_Totaux", 
                "Partages_Totaux",
                "Mentions_Partages_Totaux",
                "Mentions_Commentaires_Totaux",
                "Interactions_Totales", 
                "Taux_Clic", 
                "Taux_Interaction",
                
                # Statistiques lifetime de la page
                "Vues_Page_Totales",
                "Vues_Desktop",
                "Vues_Mobile",
                "Clics_Boutons_Desktop",
                "Clics_Boutons_Mobile",
                "Clics_Boutons_Totaux",
                
                # Vues par section
                "Vues_Accueil",
                "Vues_A_Propos",
                "Vues_Personnes",
                "Vues_Emplois",
                "Vues_Carrieres",
                "Vues_Vie_Entreprise",
                
                # Vues desktop par section
                "Vues_Desktop_Accueil",
                "Vues_Desktop_Carrieres",
                "Vues_Desktop_Emplois",
                "Vues_Desktop_Vie_Entreprise",
                
                # Vues mobile par section
                "Vues_Mobile_Accueil",
                "Vues_Mobile_Carrieres",
                "Vues_Mobile_Emplois",
                "Vues_Mobile_Vie_Entreprise"
            ]
            
            # Calculer le nombre de colonnes n√©cessaires
            num_cols = len(headers)
            print(f"   Nombre de colonnes n√©cessaires: {num_cols}")
            
            # Utiliser la feuille Sheet1 existante ou en cr√©er une nouvelle
            try:
                sheet = self.spreadsheet.worksheet("Sheet1")
                safe_sheets_operation(sheet.update_title, "Statistiques LinkedIn")
                print("   Feuille 'Sheet1' renomm√©e en 'Statistiques LinkedIn'")
            except gspread.exceptions.WorksheetNotFound:
                try:
                    sheet = self.spreadsheet.worksheet("Statistiques LinkedIn")
                    print("   Feuille 'Statistiques LinkedIn' utilis√©e pour les statistiques")
                except gspread.exceptions.WorksheetNotFound:
                    # Cr√©er une nouvelle feuille avec le bon nombre de colonnes
                    sheet = safe_sheets_operation(self.spreadsheet.add_worksheet, 
                                                title="Statistiques LinkedIn", 
                                                rows=100, 
                                                cols=num_cols)
                    print(f"   Nouvelle feuille 'Statistiques LinkedIn' cr√©√©e avec {num_cols} colonnes")
            
            # V√©rifier si la feuille a assez de colonnes, sinon l'ajuster
            current_cols = sheet.col_count
            if current_cols < num_cols:
                print(f"   Ajustement du nombre de colonnes de {current_cols} √† {num_cols}")
                safe_sheets_operation(sheet.add_cols, num_cols - current_cols)
                time.sleep(1)
                
            # Nettoyer compl√®tement la feuille
            safe_sheets_operation(sheet.clear)
            time.sleep(1)
            
            # Ajouter les en-t√™tes
            safe_sheets_operation(sheet.update, [headers], "A1")
            time.sleep(1)
            print("   En-t√™tes ajout√©s dans la feuille")
            
            # Pr√©parer les nouvelles donn√©es (UNE SEULE LIGNE)
            views = stats['page_lifetime'].get('views', {})
            
            # Utiliser la date comme STRING (pas d'objet datetime)
            new_row = [
                # Informations g√©n√©rales - Date comme string
                stats['date'],  # STRING au lieu d'objet datetime
                
                # Statistiques de partage - Nombres entiers
                stats['impressions']['total'],
                stats['impressions']['unique'],
                stats['engagement']['rate'],  # D√©cimal pour PERCENT
                stats['engagement']['clicks'],
                stats['engagement']['likes'],
                stats['engagement']['comments'],
                stats['engagement']['shares'],
                stats['engagement']['share_mentions'],
                stats['engagement']['comment_mentions'],
                stats['engagement']['total_interactions'],
                stats['engagement']['click_through_rate'],  # D√©cimal pour PERCENT
                stats['engagement']['interaction_rate'],  # D√©cimal pour PERCENT
                
                # Statistiques lifetime g√©n√©rales - Nombres entiers
                views.get('all_page_views', 0),
                views.get('desktop_page_views', 0),
                views.get('mobile_page_views', 0),
                stats['page_lifetime'].get('clicks', {}).get('desktop_button_clicks', 0),
                stats['page_lifetime'].get('clicks', {}).get('mobile_button_clicks', 0),
                stats['page_lifetime'].get('clicks', {}).get('total_button_clicks', 0),
                
                # Vues par section - Nombres entiers
                views.get('overview_page_views', 0),
                views.get('about_page_views', 0),
                views.get('people_page_views', 0),
                views.get('jobs_page_views', 0),
                views.get('careers_page_views', 0),
                views.get('life_at_page_views', 0),
                
                # Vues desktop par section - Nombres entiers
                views.get('desktop_overview_views', 0),
                views.get('desktop_careers_views', 0),
                views.get('desktop_jobs_views', 0),
                views.get('desktop_life_at_views', 0),
                
                # Vues mobile par section - Nombres entiers
                views.get('mobile_overview_views', 0),
                views.get('mobile_careers_views', 0),
                views.get('mobile_jobs_views', 0),
                views.get('mobile_life_at_views', 0)
            ]
            
            # Ajouter la ligne de donn√©es (toujours √† la ligne 2)
            safe_sheets_operation(sheet.update, [new_row], "A2")
            time.sleep(1)
            print(f"   Donn√©es lifetime mises √† jour pour la date {stats['date']}")
            
            # FORMATAGE OPTIMIS√â POUR LOOKER STUDIO avec gestion des limites
            
            # Formater les en-t√™tes
            last_col_index = len(headers) - 1
            last_col = self._get_column_letter(last_col_index)
            safe_sheets_operation(sheet.format, f'A1:{last_col}1', {
                "textFormat": {"bold": True},
                "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9}
            })
            time.sleep(1)
            
            # Formater la colonne Date (A) comme DATE
            safe_sheets_operation(sheet.format, 'A2:A2', {
                "numberFormat": {"type": "DATE", "pattern": "yyyy-mm-dd"}
            })
            time.sleep(1)
            
            # Formater les colonnes de nombres entiers comme NUMBER (avec v√©rification des limites)
            number_column_indices = [1, 2, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]
            
            for col_index in number_column_indices:
                if col_index < len(headers):  # V√©rifier que l'index est dans les limites
                    col_letter = self._get_column_letter(col_index)
                    result = safe_sheets_operation(sheet.format, f'{col_letter}2:{col_letter}2', {
                        "numberFormat": {"type": "NUMBER", "pattern": "#,##0"}
                    })
                    if result is None:  # L'op√©ration a √©t√© ignor√©e √† cause des limites
                        print(f"   ‚ö†Ô∏è Formatage ignor√© pour la colonne {col_letter} (limites d√©pass√©es)")
                    time.sleep(0.3)
            
            # Formater les colonnes de pourcentages (D=3, L=11, M=12) comme PERCENT
            percent_column_indices = [3, 11, 12]
            for col_index in percent_column_indices:
                if col_index < len(headers):  # V√©rifier que l'index est dans les limites
                    col_letter = self._get_column_letter(col_index)
                    result = safe_sheets_operation(sheet.format, f'{col_letter}2:{col_letter}2', {
                        "numberFormat": {"type": "PERCENT", "pattern": "0.00%"}
                    })
                    if result is None:  # L'op√©ration a √©t√© ignor√©e √† cause des limites
                        print(f"   ‚ö†Ô∏è Formatage ignor√© pour la colonne {col_letter} (limites d√©pass√©es)")
                    time.sleep(0.3)
            
            # Ajouter une note explicative
            try:
                note_row = 4
                note = [f"Note: Statistiques lifetime mises √† jour le {stats['date']}. Une seule ligne de donn√©es car il s'agit de donn√©es cumulatives."]
                
                safe_sheets_operation(sheet.update, [note], f"A{note_row}")
                safe_sheets_operation(sheet.format, f"A{note_row}", {
                    "textFormat": {"italic": True},
                    "backgroundColor": {"red": 0.95, "green": 0.95, "blue": 0.95}
                })
                
                # Fusionner les cellules pour la note (avec v√©rification des limites)
                if len(headers) <= sheet.col_count:
                    safe_sheets_operation(sheet.merge_cells, f"A{note_row}:{last_col}{note_row}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Impossible d'ajouter la note: {e}")
            
            print(f"\n   üìä R√©sum√©:")
            print(f"   - Donn√©es lifetime mises √† jour pour le {stats['date']}")
            print(f"   - Une seule ligne de donn√©es (√©crasement du pr√©c√©dent relev√©)")
            print(f"   - Formatage optimis√© pour Looker Studio appliqu√© ({len(headers)} colonnes)")
            
            return sheet
        except Exception as e:
            print(f"   Erreur lors de la mise √† jour de la feuille de statistiques: {e}")
            return None
    
    def _get_column_letter(self, col_idx):
        """Convertit un indice de colonne (0-based) en lettre de colonne Excel"""
        result = ""
        col_idx = col_idx + 1  # Convertir de 0-based √† 1-based
        while col_idx > 0:
            col_idx, remainder = divmod(col_idx - 1, 26)
            result = chr(65 + remainder) + result
        return result
    
    def add_share_statistics(self, stats):
        """Ajoute les statistiques de partage"""
        if not self.connect():
            print("   Impossible de se connecter √† Google Sheets. V√©rifiez vos credentials.")
            return False
            
        # V√©rifier les permissions de partage pour s'assurer que l'admin a toujours acc√®s
        self.ensure_admin_access()
        
        # Attendre un peu avant de commencer les mises √† jour
        time.sleep(2)
        
        # Mettre √† jour la feuille avec toutes les donn√©es
        sheet = self.update_stats_sheet(stats)
        if not sheet:
            print("   ‚ùå √âchec de la mise √† jour de la feuille")
            return False
        
        # URL du spreadsheet
        sheet_url = f"https://docs.google.com/spreadsheets/d/{self.spreadsheet.id}"
        print(f"   URL du tableau: {sheet_url}")
        
        return True


def verify_token(access_token):
    """V√©rifie si le token d'acc√®s est valide"""
    headers = {
        "Authorization": f"Bearer {access_token}",
        "X-Restli-Protocol-Version": "2.0.0",
        "LinkedIn-Version": "202312"
    }
    
    url = "https://api.linkedin.com/v2/me"
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            return True, response.json()
        else:
            return False, f"Erreur {response.status_code}: {response.text}"
    except Exception as e:
        return False, str(e)


class MultiOrganizationShareTracker:
    """Gestionnaire pour les statistiques de partage de plusieurs organisations LinkedIn"""
    
    def __init__(self, config_file='organizations_config.json'):
        """Initialise le tracker multi-organisations"""
        self.config_file = config_file
        self.organizations = self.load_organizations()
        self.access_token = os.getenv("LINKEDIN_ACCESS_TOKEN", "").strip("'")
        self.admin_email = os.getenv("GOOGLE_ADMIN_EMAIL", "byteberry.analytics@gmail.com")
        self.share_mapping_file = 'share_stats_mapping.json'  # Fichier de mapping sp√©cifique pour les stats de partage
        
    def load_organizations(self):
        """Charge la configuration des organisations depuis un fichier JSON"""
        try:
            # D'abord essayer de charger depuis un fichier local
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            
            # Sinon, charger depuis une variable d'environnement
            orgs_json = os.getenv("LINKEDIN_ORGANIZATIONS_CONFIG")
            if orgs_json:
                return json.loads(orgs_json)
            
            # Configuration par d√©faut
            print("Aucune configuration trouv√©e, utilisation de la configuration par d√©faut")
            return []
            
        except Exception as e:
            print(f"Erreur lors du chargement de la configuration: {e}")
            return []
    
    def get_sheet_info_for_org(self, org_id, org_name):
        """R√©cup√®re ou cr√©e l'ID et le nom du Google Sheet pour une organisation"""
        try:
            if os.path.exists(self.share_mapping_file):
                with open(self.share_mapping_file, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
            else:
                mapping = {}
            
            # Si l'organisation a d√©j√† un sheet ID, le retourner
            if org_id in mapping:
                print(f"   üìÇ R√©utilisation du Google Sheet existant")
                return mapping[org_id]['sheet_id'], mapping[org_id]['sheet_name']
            
            # Sinon, utiliser le nom par d√©faut
            clean_name = org_name.replace(' ', '_').replace('‚Ñ¢', '').replace('/', '_')
            sheet_name = f"LinkedIn_Share_Stats_{clean_name}_{org_id}"
            
            # Stocker le mapping pour la prochaine fois
            mapping[org_id] = {
                'sheet_name': sheet_name,
                'sheet_id': None,  # Sera mis √† jour apr√®s cr√©ation
                'org_name': org_name
            }
            
            with open(self.share_mapping_file, 'w', encoding='utf-8') as f:
                json.dump(mapping, f, indent=2, ensure_ascii=False)
            
            return None, sheet_name
            
        except Exception as e:
            print(f"Erreur dans la gestion du mapping: {e}")
            clean_name = org_name.replace(' ', '_').replace('‚Ñ¢', '').replace('/', '_')
            sheet_name = f"LinkedIn_Share_Stats_{clean_name}_{org_id}"
            return None, sheet_name
    
    def update_sheet_mapping(self, org_id, sheet_id):
        """Met √† jour le mapping avec l'ID du sheet cr√©√©"""
        try:
            if os.path.exists(self.share_mapping_file):
                with open(self.share_mapping_file, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
            else:
                mapping = {}
            
            if org_id in mapping:
                mapping[org_id]['sheet_id'] = sheet_id
                mapping[org_id]['sheet_url'] = f"https://docs.google.com/spreadsheets/d/{sheet_id}"
                
                with open(self.share_mapping_file, 'w', encoding='utf-8') as f:
                    json.dump(mapping, f, indent=2, ensure_ascii=False)
                    
        except Exception as e:
            print(f"Erreur lors de la mise √† jour du mapping: {e}")
    
    def process_all_organizations(self):
        """Traite toutes les organisations configur√©es"""
        if not self.access_token:
            print("Erreur: LINKEDIN_ACCESS_TOKEN manquant")
            return False
        
        # V√©rifier le token une seule fois
        print("\n--- V√©rification du token ---")
        is_valid, result = verify_token(self.access_token)
        
        if not is_valid:
            print(f"‚ùå Token invalide: {result}")
            return False
        
        print("‚úÖ Token valide!")
        user_info = result
        print(f"   Utilisateur: {user_info.get('localizedFirstName', '')} {user_info.get('localizedLastName', '')}")
        
        # Traiter chaque organisation
        results = []
        total_orgs = len(self.organizations)
        successful_urls = []
        
        for idx, org in enumerate(self.organizations, 1):
            org_id = org['id']
            org_name = org['name']
            
            print(f"\n{'='*60}")
            print(f"[{idx}/{total_orgs}] Traitement de: {org_name}")
            print(f"ID: {org_id}")
            print(f"{'='*60}")
            
            try:
                sheet_url = self.process_single_organization(org_id, org_name)
                if sheet_url:
                    results.append({
                        'org_id': org_id,
                        'org_name': org_name,
                        'success': True,
                        'sheet_url': sheet_url,
                        'timestamp': datetime.now().isoformat()
                    })
                    successful_urls.append({
                        'name': org_name,
                        'url': sheet_url
                    })
                else:
                    results.append({
                        'org_id': org_id,
                        'org_name': org_name,
                        'success': False,
                        'timestamp': datetime.now().isoformat()
                    })
                    
                # Attendre entre chaque organisation pour √©viter les probl√®mes de quota
                if idx < total_orgs:  # Ne pas attendre apr√®s la derni√®re organisation
                    print(f"   ‚è≥ Attente de 5 secondes avant la prochaine organisation...")
                    time.sleep(5)
                    
            except Exception as e:
                print(f"‚ùå Erreur lors du traitement de {org_name}: {e}")
                results.append({
                    'org_id': org_id,
                    'org_name': org_name,
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
        
        # R√©sum√©
        print(f"\n{'='*60}")
        print("R√âSUM√â DU TRAITEMENT - STATISTIQUES DE PARTAGE")
        print(f"{'='*60}")
        
        successful = sum(1 for r in results if r['success'])
        failed = len(results) - successful
        
        print(f"‚úÖ Organisations trait√©es avec succ√®s: {successful}/{total_orgs}")
        if failed > 0:
            print(f"‚ùå Organisations en √©chec: {failed}/{total_orgs}")
        
        if failed > 0:
            print("\nD√©tail des √©checs:")
            for r in results:
                if not r['success']:
                    error_msg = r.get('error', 'Erreur inconnue')
                    print(f"  - {r['org_name']}: {error_msg}")
        
        # Afficher les URLs des sheets cr√©√©s
        if successful > 0:
            print("\nüìä Google Sheets de statistiques de partage cr√©√©s/mis √† jour:")
            if os.path.exists(self.share_mapping_file):
                with open(self.share_mapping_file, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
                
                for r in results:
                    if r['success'] and r['org_id'] in mapping:
                        sheet_info = mapping[r['org_id']]
                        if sheet_info.get('sheet_id'):
                            print(f"  - {r['org_name']}:")
                            url = sheet_info.get('sheet_url') or f"https://docs.google.com/spreadsheets/d/{sheet_info['sheet_id']}"
                            print(f"    {url}")
        
        return successful > 0
    
    def process_single_organization(self, org_id, org_name):
        """Traite une organisation unique"""
        # Obtenir le nom du sheet pour cette organisation
        sheet_id, sheet_name = self.get_sheet_info_for_org(org_id, org_name)
        
        print(f"\nüìä Google Sheet: {sheet_name}")
        
        # Initialisation du tracker
        tracker = LinkedInShareStatisticsTracker(self.access_token, org_id, sheet_name)
        
        # 1. Obtention des statistiques de partage
        print("\n1. R√©cup√©ration des statistiques cumulatives de partage...")
        raw_share_stats = tracker.get_share_statistics()
        
        # 2. Obtention des statistiques lifetime de la page
        print("\n2. R√©cup√©ration des statistiques lifetime de la page...")
        raw_page_stats = tracker.get_page_statistics()
        
        if raw_share_stats or raw_page_stats:
            # Traitement des donn√©es
            print("\n3. Analyse des donn√©es statistiques...")
            stats = tracker.parse_share_statistics(raw_share_stats, raw_page_stats)
            
            # Afficher un aper√ßu des donn√©es
            print("\nüìà Aper√ßu des statistiques:")
            print(f"   Date de mesure: {stats['date']}")
            print(f"   Impressions totales: {stats['impressions']['total']}")
            print(f"   Taux d'engagement: {stats['engagement']['rate']:.2%}")
            print(f"   Total interactions: {stats['engagement']['total_interactions']}")
            
            # Chemin vers les credentials
            credentials_path = Path(__file__).resolve().parent / 'credentials' / 'service_account_credentials.json'
            
            # Pour Google Cloud Run, utiliser le chemin mont√©
            if os.getenv('K_SERVICE'):  # Variable d'environnement de Cloud Run
                credentials_path = Path('/app/credentials/service_account_credentials.json')
            
            if not credentials_path.exists():
                # Essayer de cr√©er les credentials depuis une variable d'environnement
                creds_json = os.getenv('GOOGLE_SERVICE_ACCOUNT_JSON')
                if creds_json:
                    credentials_path.parent.mkdir(parents=True, exist_ok=True)
                    with open(credentials_path, 'w') as f:
                        f.write(creds_json)
                    print("   ‚úÖ Credentials cr√©√©s depuis la variable d'environnement")
                else:
                    print(f"   ‚ùå Erreur: Fichier de credentials non trouv√©: {credentials_path}")
                    return None
            else:
                print("   ‚úÖ Credentials trouv√©s")
            
            # 4. Export vers Google Sheets
            print("\n4. Export vers Google Sheets...")
            exporter = GoogleSheetsExporter(tracker.sheet_name, credentials_path, self.admin_email)
            success = exporter.add_share_statistics(stats)
            
            if success and exporter.spreadsheet:
                # Mettre √† jour le mapping avec l'ID du sheet
                self.update_sheet_mapping(org_id, exporter.spreadsheet.id)
                sheet_url = f"https://docs.google.com/spreadsheets/d/{exporter.spreadsheet.id}"
                print(f"\n‚úÖ Export r√©ussi pour {org_name}!")
                print(f"üìä URL du Sheet: {sheet_url}")
                return sheet_url
            else:
                print(f"\n‚ùå √âchec de l'export pour {org_name}")
                return None
        else:
            print("‚ùå Impossible de r√©cup√©rer les statistiques")
            return None


def main():
    """Fonction principale"""
    print("="*60)
    print("LINKEDIN MULTI-ORGANISATION SHARE STATISTICS TRACKER")
    print("="*60)
    print(f"Date d'ex√©cution: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Cr√©er le tracker
    tracker = MultiOrganizationShareTracker()
    
    if not tracker.organizations:
        print("\n‚ùå Aucune organisation configur√©e!")
        print("\nPour configurer des organisations:")
        print("1. Lancez d'abord: python3 discover_organizations.py")
        print("2. Ou cr√©ez manuellement 'organizations_config.json' avec le format:")
        print(json.dumps([
            {"id": "123456", "name": "Entreprise A"},
            {"id": "789012", "name": "Entreprise B"}
        ], indent=2))
        sys.exit(1)
    
    print(f"\nüìã Organisations configur√©es: {len(tracker.organizations)}")
    for org in tracker.organizations:
        print(f"   - {org['name']} (ID: {org['id']})")
    
    print(f"\n‚öôÔ∏è  Configuration:")
    print(f"   - Email admin: {tracker.admin_email}")
    print(f"   - Type de donn√©es: Statistiques cumulatives de partage (lifetime)")
    print(f"   - Formatage: Optimis√© pour Looker Studio")
    print(f"   - Mode: Une seule ligne par organisation (√©crasement)")
    
    # Demander confirmation si plus de 5 organisations
    if len(tracker.organizations) > 5:
        print(f"\n‚ö†Ô∏è  Attention: {len(tracker.organizations)} organisations √† traiter.")
        print("   Cela peut prendre du temps et consommer des quotas API.")
        response = input("   Continuer ? (o/N): ")
        if response.lower() != 'o':
            print("Annul√©.")
            sys.exit(0)
    
    print("\nüöÄ D√©marrage du traitement des statistiques de partage...")
    print("‚è≥ Note: Le traitement inclut des d√©lais pour respecter les quotas Google Sheets")
    
    # Lancer le traitement
    start_time = datetime.now()
    success = tracker.process_all_organizations()
    end_time = datetime.now()
    
    # Afficher le temps d'ex√©cution
    duration = end_time - start_time
    minutes = int(duration.total_seconds() // 60)
    seconds = int(duration.total_seconds() % 60)
    
    print(f"\n‚è±Ô∏è  Temps d'ex√©cution: {minutes}m {seconds}s")
    
    if success:
        print("\nüìä Les Google Sheets sont maintenant optimis√©s pour Looker Studio avec:")
        print("   ‚úÖ Formatage des dates (DATE)")
        print("   ‚úÖ Formatage des nombres (NUMBER)")
        print("   ‚úÖ Formatage des pourcentages (PERCENT)")
        print("   ‚úÖ Noms de colonnes sans espaces ni caract√®res sp√©ciaux")
        print("   ‚úÖ Types de donn√©es coh√©rents pour chaque colonne")
        print("   ‚úÖ Une seule ligne de donn√©es par organisation (lifetime)")
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()