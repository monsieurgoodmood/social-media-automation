#!/usr/bin/env python3
"""
LinkedIn Multi-Organization Page Statistics Tracker
Ce script collecte les statistiques des vues de page LinkedIn par pays, s√©niorit√© et industrie
pour plusieurs organisations et les enregistre dans Google Sheets.
"""

import os
import requests
import urllib.parse
import json
from datetime import datetime
import time
from pathlib import Path
import sys
from dotenv import load_dotenv
import random

# Pour Google Sheets
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from gspread.exceptions import APIError

# Chargement des variables d'environnement
load_dotenv()

def get_column_letter(col_idx):
    """Convertit un indice de colonne (0-based) en lettre de colonne pour Google Sheets (A, B, ..., Z, AA, AB, ...)"""
    result = ""
    col_idx = col_idx + 1  # Convertir de 0-based √† 1-based
    while col_idx > 0:
        col_idx, remainder = divmod(col_idx - 1, 26)
        result = chr(65 + remainder) + result
    return result

def safe_sheets_operation(operation, *args, max_retries=5, **kwargs):
    """
    Ex√©cute une op√©ration Google Sheets avec gestion des erreurs de quota
    """
    for attempt in range(max_retries):
        try:
            return operation(*args, **kwargs)
        except APIError as e:
            if '429' in str(e) or 'Quota exceeded' in str(e):
                # Calcul du d√©lai d'attente avec backoff exponentiel + jitter
                base_delay = min(60, (2 ** attempt) * 5)  # Maximum 60 secondes
                jitter = random.uniform(0.5, 1.5)  # Ajouter du jitter pour √©viter la synchronisation
                delay = base_delay * jitter
                
                print(f"   ‚è≥ Quota d√©pass√© (tentative {attempt + 1}/{max_retries}), attente de {delay:.1f}s...")
                time.sleep(delay)
                
                if attempt == max_retries - 1:
                    print(f"   ‚ùå √âchec apr√®s {max_retries} tentatives: {e}")
                    raise
            else:
                print(f"   ‚ùå Erreur API non li√©e au quota: {e}")
                raise
        except Exception as e:
            print(f"   ‚ùå Erreur inattendue: {e}")
            if attempt == max_retries - 1:
                raise
            time.sleep(2)

class LinkedInPageStatisticsTracker:
    """Classe pour suivre les statistiques des vues de page LinkedIn par cat√©gorie"""
    
    def __init__(self, access_token, organization_id, sheet_name=None):
        """Initialise le tracker avec le token d'acc√®s et l'ID de l'organisation"""
        self.access_token = access_token
        self.organization_id = organization_id
        self.sheet_name = sheet_name or f"LinkedIn_Page_Stats_{organization_id}"
        self.base_url = "https://api.linkedin.com/v2"
        
    def get_headers(self):
        """Retourne les en-t√™tes pour les requ√™tes API"""
        return {
            "Authorization": f"Bearer {self.access_token}",
            "X-Restli-Protocol-Version": "2.0.0",
            "LinkedIn-Version": "202312",
            "Content-Type": "application/json"
        }
    
    def get_page_statistics(self):
        """Obtient les statistiques de vues de page pour l'organisation"""
        # Encoder l'URN de l'organisation
        organization_urn = f"urn:li:organization:{self.organization_id}"
        encoded_urn = urllib.parse.quote(organization_urn)
        
        # Construire l'URL
        url = f"{self.base_url}/organizationPageStatistics?q=organization&organization={encoded_urn}"
        
        # Effectuer la requ√™te avec gestion des erreurs et retry
        max_retries = 3
        retry_delay = 2  # secondes
        
        for attempt in range(max_retries):
            try:
                response = requests.get(url, headers=self.get_headers())
                
                if response.status_code == 200:
                    data = response.json()
                    print(f"   Donn√©es de statistiques de page r√©cup√©r√©es avec succ√®s")
                    return data
                    
                elif response.status_code == 429:
                    # Rate limit, attendre avant de r√©essayer
                    print(f"   Rate limit atteint, attente de {retry_delay} secondes...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Backoff exponentiel
                else:
                    print(f"   Erreur API: {response.status_code} - {response.text}")
                    time.sleep(retry_delay)
                    retry_delay *= 2
                    
            except Exception as e:
                print(f"   Exception lors de la requ√™te: {e}")
                time.sleep(retry_delay)
                retry_delay *= 2
        
        print("   √âchec apr√®s plusieurs tentatives pour obtenir les statistiques de page.")
        return None
    
    def parse_page_statistics(self, data):
        """Analyse les donn√©es de l'API et extrait les statistiques pertinentes"""
        stats = {}
        
        # Date de r√©cup√©ration
        stats['date'] = datetime.now().strftime('%Y-%m-%d')
        
        # S'assurer que les donn√©es sont valides
        if not data or 'elements' not in data or len(data['elements']) == 0:
            print("   Aucune donn√©e de statistiques valide trouv√©e.")
            return stats
        
        # Obtenir le premier √©l√©ment (qui contient toutes les stats)
        element = data['elements'][0]
        
        # 1. Statistiques par pays
        stats['by_country'] = {}
        if 'pageStatisticsByCountry' in element:
            for item in element['pageStatisticsByCountry']:
                country = item.get('country', 'unknown')
                country_code = country.split(':')[-1] if ':' in country else country
                country_name = self._get_country_name(country_code)
                
                views = item.get('pageStatistics', {}).get('views', {})
                
                # Extraire les donn√©es de vues pertinentes
                total_views = views.get('allPageViews', {}).get('pageViews', 0)
                desktop_views = views.get('allDesktopPageViews', {}).get('pageViews', 0)
                mobile_views = views.get('allMobilePageViews', {}).get('pageViews', 0)
                
                # D√©tails par type de page
                overview_views = views.get('overviewPageViews', {}).get('pageViews', 0)
                about_views = views.get('aboutPageViews', {}).get('pageViews', 0)
                people_views = views.get('peoplePageViews', {}).get('pageViews', 0)
                jobs_views = views.get('jobsPageViews', {}).get('pageViews', 0)
                careers_views = views.get('careersPageViews', {}).get('pageViews', 0)
                
                stats['by_country'][country_code] = {
                    'name': country_name,
                    'total_views': total_views,
                    'desktop_views': desktop_views,
                    'mobile_views': mobile_views,
                    'overview_views': overview_views,
                    'about_views': about_views,
                    'people_views': people_views,
                    'jobs_views': jobs_views,
                    'careers_views': careers_views
                }
        
        # 2. Statistiques par niveau de s√©niorit√©
        stats['by_seniority'] = {}
        if 'pageStatisticsBySeniority' in element:
            for item in element['pageStatisticsBySeniority']:
                seniority = item.get('seniority', 'unknown')
                seniority_id = seniority.split(':')[-1] if ':' in seniority else seniority
                seniority_name = self._get_seniority_description(seniority_id)
                
                views = item.get('pageStatistics', {}).get('views', {})
                
                # Extraire les donn√©es de vues pertinentes
                total_views = views.get('allPageViews', {}).get('pageViews', 0)
                desktop_views = views.get('allDesktopPageViews', {}).get('pageViews', 0)
                mobile_views = views.get('allMobilePageViews', {}).get('pageViews', 0)
                
                # D√©tails par type de page
                overview_views = views.get('overviewPageViews', {}).get('pageViews', 0)
                about_views = views.get('aboutPageViews', {}).get('pageViews', 0)
                people_views = views.get('peoplePageViews', {}).get('pageViews', 0)
                jobs_views = views.get('jobsPageViews', {}).get('pageViews', 0)
                careers_views = views.get('careersPageViews', {}).get('pageViews', 0)
                
                stats['by_seniority'][seniority_id] = {
                    'name': seniority_name,
                    'total_views': total_views,
                    'desktop_views': desktop_views,
                    'mobile_views': mobile_views,
                    'overview_views': overview_views,
                    'about_views': about_views,
                    'people_views': people_views,
                    'jobs_views': jobs_views,
                    'careers_views': careers_views
                }
        
        # 3. Statistiques par industrie
        stats['by_industry'] = {}
        if 'pageStatisticsByIndustry' in element:
            for item in element['pageStatisticsByIndustry']:
                industry = item.get('industry', 'unknown')
                industry_id = industry.split(':')[-1] if ':' in industry else industry
                industry_name = self._get_industry_description(industry_id)
                
                views = item.get('pageStatistics', {}).get('views', {})
                
                # Extraire les donn√©es de vues pertinentes
                total_views = views.get('allPageViews', {}).get('pageViews', 0)
                desktop_views = views.get('allDesktopPageViews', {}).get('pageViews', 0)
                mobile_views = views.get('allMobilePageViews', {}).get('pageViews', 0)
                
                # D√©tails par type de page
                overview_views = views.get('overviewPageViews', {}).get('pageViews', 0)
                about_views = views.get('aboutPageViews', {}).get('pageViews', 0)
                people_views = views.get('peoplePageViews', {}).get('pageViews', 0)
                jobs_views = views.get('jobsPageViews', {}).get('pageViews', 0)
                careers_views = views.get('careersPageViews', {}).get('pageViews', 0)
                
                stats['by_industry'][industry_id] = {
                    'name': industry_name,
                    'total_views': total_views,
                    'desktop_views': desktop_views,
                    'mobile_views': mobile_views,
                    'overview_views': overview_views,
                    'about_views': about_views,
                    'people_views': people_views,
                    'jobs_views': jobs_views,
                    'careers_views': careers_views
                }
                
        # 4. Calcul des totaux globaux
        total_page_views = 0
        total_desktop_views = 0
        total_mobile_views = 0
        total_overview_views = 0
        total_about_views = 0
        total_people_views = 0
        total_jobs_views = 0
        total_careers_views = 0
        
        # Utiliser les donn√©es par pays pour le total (le plus fiable)
        for country_code, country_data in stats['by_country'].items():
            total_page_views += country_data['total_views']
            total_desktop_views += country_data['desktop_views']
            total_mobile_views += country_data['mobile_views']
            total_overview_views += country_data['overview_views']
            total_about_views += country_data['about_views']
            total_people_views += country_data['people_views']
            total_jobs_views += country_data['jobs_views']
            total_careers_views += country_data['careers_views']
        
        stats['totals'] = {
            'total_page_views': total_page_views,
            'total_desktop_views': total_desktop_views,
            'total_mobile_views': total_mobile_views,
            'total_overview_views': total_overview_views,
            'total_about_views': total_about_views,
            'total_people_views': total_people_views,
            'total_jobs_views': total_jobs_views,
            'total_careers_views': total_careers_views
        }
        
        return stats
    
    def _get_country_name(self, country_code):
        """Obtient le nom du pays √† partir du code pays"""
        countries = {
            'ae': '√âmirats arabes unis',
            'ar': 'Argentine',
            'at': 'Autriche',
            'au': 'Australie',
            'be': 'Belgique',
            'bf': 'Burkina Faso',
            'br': 'Br√©sil',
            'ca': 'Canada',
            'ch': 'Suisse',
            'ci': 'C√¥te d\'Ivoire',
            'cl': 'Chili',
            'cm': 'Cameroun',
            'cn': 'Chine',
            'co': 'Colombie',
            'cz': 'R√©publique tch√®que',
            'de': 'Allemagne',
            'dk': 'Danemark',
            'dz': 'Alg√©rie',
            'eg': '√âgypte',
            'es': 'Espagne',
            'fi': 'Finlande',
            'fr': 'France',
            'gb': 'Royaume-Uni',
            'gr': 'Gr√®ce',
            'hk': 'Hong Kong',
            'hu': 'Hongrie',
            'id': 'Indon√©sie',
            'ie': 'Irlande',
            'il': 'Isra√´l',
            'in': 'Inde',
            'it': 'Italie',
            'jp': 'Japon',
            'kr': 'Cor√©e du Sud',
            'lu': 'Luxembourg',
            'ma': 'Maroc',
            'mg': 'Madagascar',
            'mx': 'Mexique',
            'my': 'Malaisie',
            'ng': 'Nigeria',
            'nl': 'Pays-Bas',
            'no': 'Norv√®ge',
            'nz': 'Nouvelle-Z√©lande',
            'ph': 'Philippines',
            'pl': 'Pologne',
            'pt': 'Portugal',
            'ro': 'Roumanie',
            'ru': 'Russie',
            'sa': 'Arabie saoudite',
            'se': 'Su√®de',
            'sg': 'Singapour',
            'th': 'Tha√Ølande',
            'tn': 'Tunisie',
            'tr': 'Turquie',
            'tw': 'Ta√Øwan',
            'ua': 'Ukraine',
            'us': '√âtats-Unis',
            'vn': 'Vietnam',
            'za': 'Afrique du Sud'
        }
        return countries.get(country_code.lower(), f"Pays {country_code}")
    
    def _get_seniority_description(self, seniority_id):
        """Fournit une description pour les niveaux de s√©niorit√©"""
        seniority_map = {
            "1": "Stagiaire",
            "2": "D√©butant",
            "3": "Junior",
            "4": "Interm√©diaire",
            "5": "Senior",
            "6": "Chef d'√©quipe",
            "7": "Directeur",
            "8": "Vice-pr√©sident",
            "9": "C-suite",
            "10": "Cadre dirigeant"
        }
        return seniority_map.get(seniority_id, f"Niveau {seniority_id}")
    
    def _get_industry_description(self, industry_id):
        """Fournit une description pour les identifiants d'industrie"""
        industry_map = {
            "1": "Agriculture",
            "2": "√âlevage",
            "3": "P√™che et aquaculture",
            "4": "Banque",
            "5": "Services de t√©l√©communications",
            "6": "Construction",
            "7": "Coop√©ratives",
            "8": "√âducation pr√©scolaire et primaire",
            "9": "√âducation coll√©giale",
            "10": "√âducation secondaire",
            "11": "√âducation",
            "12": "Divertissement",
            "13": "Environnement",
            "14": "Finance",
            "15": "Gouvernement",
            "16": "Sant√©",
            "17": "Industrie manufacturi√®re",
            "18": "M√©dias",
            "19": "Mines et m√©taux",
            "20": "Commerce de d√©tail",
            "21": "Transport",
            "22": "Sports",
            "23": "√âlectronique",
            "24": "√ânergie",
            "25": "H√¥pitaux et sant√©",
            "26": "Assurance",
            "27": "Technologies et services de l'information",
            "28": "Luxe et bijoux",
            "29": "Machinerie",
            "30": "Maritime",
            "31": "Sant√© et bien-√™tre",
            "32": "Services juridiques",
            "33": "Biblioth√®ques",
            "34": "Logistique et cha√Æne d'approvisionnement",
            "35": "Mat√©riaux",
            "36": "Industrie militaire",
            "37": "Industrie musicale",
            "38": "Nanotechnologie",
            "39": "Journaux",
            "40": "Organisation √† but non lucratif",
            "41": "P√©trole et √©nergie",
            "42": "Services en ligne",
            "43": "Outsourcing/Offshoring",
            "44": "Emballage et conteneurs",
            "45": "Papier et produits forestiers",
            "46": "Services philanthropiques",
            "47": "Photographie",
            "48": "Marketing et publicit√©",
            "49": "Imprimerie",
            "50": "Biens de consommation",
            "51": "√âdition",
            "52": "Chemins de fer",
            "53": "Organisation √† but non lucratif",
            "54": "Recherche",
            "55": "Restaurants",
            "56": "S√©curit√© et investigations",
            "57": "Semi-conducteurs",
            "58": "Transport maritime",
            "59": "Textiles",
            "60": "Mode et v√™tements",
            "61": "Arts",
            "62": "Fabrication de moteurs de v√©hicules",
            "63": "Vins et spiritueux",
            "64": "Industrie du fil et de la fibre",
            "65": "Industrie a√©ronautique et a√©rospatiale",
            "66": "Automobile",
            "67": "G√©nie civil",
            "68": "Comptabilit√©",
            "69": "Services financiers",
            "70": "Aviation",
            "71": "Architecture et urbanisme",
            "72": "Biotechnologie",
            "73": "Construction navale",
            "74": "Produits chimiques",
            "75": "Internet",
            "76": "√âquipements √©lectriques/√©lectroniques",
            "77": "Gestion de l'environnement",
            "78": "Produits alimentaires",
            "79": "Collecte de fonds",
            "80": "Jeux vid√©o et √©lectroniques",
            "81": "H√¥tellerie",
            "82": "Mobilier d'entreprise",
            "83": "Intelligence artificielle",
            "84": "Industrie pharmaceutique",
            "85": "Plastiques",
            "86": "Commerce international et d√©veloppement",
            "87": "Industrie du vin et des spiritueux",
            "88": "Commerce de gros",
            "89": "√âlevage d'animaux",
            "90": "Gestion des march√©s",
            "91": "Affaires politiques",
            "92": "Ressources humaines",
            "93": "Industrie laiti√®re",
            "94": "Design",
            "95": "Services aux consommateurs",
            "96": "Logiciels informatiques",
            "97": "√âv√©nements",
            "98": "Arts et artisanat",
            "99": "Formation professionnelle et coaching",
            "100": "Affaires gouvernementales",
            "101": "Meubles",
            "102": "√âquipement de loisir",
            "103": "Mat√©riel de bureau",
            "104": "R√©seaux informatiques",
            "105": "Relations publiques et communications",
            "106": "Activit√©s de loisirs",
            "107": "Immobilier",
            "108": "√âquipement sportif",
            "109": "Vente en gros",
            "110": "Services publics",
            "111": "Animation",
            "112": "Produits cosm√©tiques",
            "113": "≈íuvres de bienfaisance",
            "114": "Industrie du b√©tail",
            "115": "Arts de la sc√®ne",
            "116": "Gestion des installations",
            "117": "Design graphique",
            "118": "√âquipement m√©dical",
            "119": "Conseil",
            "120": "Industrie du bois",
            "121": "Industrie de la construction",
            "122": "Enseignement sup√©rieur",
            "123": "Promotion immobili√®re",
            "124": "Gestion de placements",
            "125": "Services m√©dicaux",
            "126": "Services v√©t√©rinaires",
            "127": "Commerce de d√©tail",
            "128": "G√©nie √©lectrique",
            "129": "Informatique et r√©seau de s√©curit√©",
            "130": "Mat√©riel informatique",
            "131": "B√¢timent et travaux publics",
            "132": "Traduction et localisation",
            "133": "Programmation informatique",
            "134": "Architecture",
            "135": "Relations publiques et communications",
            "136": "Exploitation mini√®re",
            "137": "Design",
            "138": "Sant√©, bien-√™tre et fitness",
            "139": "E-learning",
            "140": "Services bancaires d'investissement",
            "141": "Mus√©es et institutions",
            "142": "V√©t√©rinaire",
            "143": "Industrie du voyage",
            "144": "Technologies de l'information et services",
            "145": "Gestion de l'√©ducation",
            "147": "D√©veloppement Web",
            "148": "Technologies et services de l'information"
        }
        return industry_map.get(industry_id, f"Industrie {industry_id}")


class GoogleSheetsExporter:
    """Classe pour exporter les donn√©es vers Google Sheets"""
    
    def __init__(self, spreadsheet_name, credentials_path, admin_email="byteberry.analytics@gmail.com"):
        """Initialise l'exportateur avec le nom du spreadsheet et le chemin des credentials"""
        self.spreadsheet_name = spreadsheet_name
        self.credentials_path = credentials_path
        self.admin_email = admin_email
        self.client = None
        self.spreadsheet = None
        
    def connect(self):
        """√âtablit la connexion avec Google Sheets API"""
        try:
            scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
            creds = ServiceAccountCredentials.from_json_keyfile_name(str(self.credentials_path), scope)
            self.client = gspread.authorize(creds)
            
            # V√©rifier si le spreadsheet existe d√©j√†, sinon le cr√©er
            try:
                self.spreadsheet = self.client.open(self.spreadsheet_name)
                print(f"   Spreadsheet existant trouv√©: {self.spreadsheet_name}")
            except gspread.exceptions.SpreadsheetNotFound:
                self.spreadsheet = safe_sheets_operation(self.client.create, self.spreadsheet_name)
                print(f"   Nouveau spreadsheet cr√©√©: {self.spreadsheet_name}")
                
                # Donner l'acc√®s en √©dition √† l'adresse e-mail sp√©cifi√©e
                safe_sheets_operation(self.spreadsheet.share, self.admin_email, perm_type="user", role="writer")
                print(f"   Acc√®s en √©dition accord√© √† {self.admin_email}")
            
            # V√©rifier si Sheet1 existe et le renommer en "R√©sum√©"
            try:
                sheet1 = self.spreadsheet.worksheet("Sheet1")
                safe_sheets_operation(sheet1.update_title, "R√©sum√©")
                print("   Feuille 'Sheet1' renomm√©e en 'R√©sum√©'")
            except gspread.exceptions.WorksheetNotFound:
                pass  # Sheet1 n'existe pas, pas besoin de la renommer
            
            return True
        except Exception as e:
            print(f"   Erreur de connexion √† Google Sheets: {e}")
            return False
    
    def ensure_admin_access(self):
        """V√©rifie et garantit que l'admin a toujours acc√®s au document"""
        try:
            # R√©cup√©rer les permissions actuelles
            permissions = safe_sheets_operation(self.spreadsheet.list_permissions)
            
            # V√©rifier si l'email admin est d√©j√† dans les permissions
            admin_has_access = False
            for permission in permissions:
                if 'emailAddress' in permission and permission['emailAddress'] == self.admin_email:
                    admin_has_access = True
                    # V√©rifier si le r√¥le est au moins "writer"
                    if permission.get('role') not in ['writer', 'owner']:
                        # Mettre √† jour le r√¥le si n√©cessaire
                        safe_sheets_operation(self.spreadsheet.share, self.admin_email, perm_type="user", role="writer")
                        print(f"   R√¥le mis √† jour pour {self.admin_email} (writer)")
                    break
            
            # Si l'admin n'a pas encore acc√®s, lui donner
            if not admin_has_access:
                safe_sheets_operation(self.spreadsheet.share, self.admin_email, perm_type="user", role="writer")
                print(f"   Acc√®s en √©dition accord√© √† {self.admin_email}")
                
        except Exception as e:
            print(f"   Erreur lors de la v√©rification des permissions: {e}")
    
    def format_sheet_for_looker(self, sheet, headers, data_start_row=2):
        """Applique le formatage appropri√© aux colonnes pour que Looker d√©tecte correctement les types"""
        try:
            # D√©finir les indices des colonnes selon leur type
            date_columns = [0]  # Colonne A (Date)
            text_columns = [1, 2]  # Colonnes B et C (Pays/Niveau/Industrie et Code/Description)
            number_columns = list(range(3, len(headers)))  # Toutes les autres colonnes sont num√©riques
            
            # Formater la colonne date
            for col_idx in date_columns:
                col_letter = get_column_letter(col_idx)
                range_name = f"{col_letter}{data_start_row}:{col_letter}"
                safe_sheets_operation(sheet.format, range_name, {
                    "numberFormat": {
                        "type": "DATE",
                        "pattern": "yyyy-mm-dd"
                    }
                })
            
            # Formater les colonnes de texte
            for col_idx in text_columns:
                if col_idx < len(headers):  # V√©rifier que l'index existe
                    col_letter = get_column_letter(col_idx)
                    range_name = f"{col_letter}{data_start_row}:{col_letter}"
                    safe_sheets_operation(sheet.format, range_name, {
                        "numberFormat": {
                            "type": "TEXT"
                        }
                    })
            
            # Formater les colonnes num√©riques
            for col_idx in number_columns:
                col_letter = get_column_letter(col_idx)
                range_name = f"{col_letter}{data_start_row}:{col_letter}"
                safe_sheets_operation(sheet.format, range_name, {
                    "numberFormat": {
                        "type": "NUMBER",
                        "pattern": "#,##0"
                    }
                })
            
            print("   ‚úì Formatage appliqu√© pour Looker")
            
        except Exception as e:
            print(f"   Erreur lors du formatage des colonnes: {e}")
    
    def prepare_and_update_summary_sheet(self, stats):
        """Pr√©pare et met √† jour la feuille de r√©sum√© des statistiques"""
        try:
            # V√©rifier si la feuille R√©sum√© existe et l'utiliser
            try:
                sheet = self.spreadsheet.worksheet("R√©sum√©")
                print("   Feuille 'R√©sum√©' utilis√©e pour le r√©sum√©")
            except gspread.exceptions.WorksheetNotFound:
                try:
                    sheet = self.spreadsheet.worksheet("Sheet1")
                    safe_sheets_operation(sheet.update_title, "R√©sum√©")
                    print("   Feuille par d√©faut 'Sheet1' renomm√©e en 'R√©sum√©'")
                except gspread.exceptions.WorksheetNotFound:
                    sheet = safe_sheets_operation(self.spreadsheet.add_worksheet, title="R√©sum√©", rows=100, cols=10)
                    print("   Nouvelle feuille 'R√©sum√©' cr√©√©e")
            
            # Nettoyer la feuille existante
            safe_sheets_operation(sheet.clear)
            
            # Attendre un peu pour √©viter les probl√®mes de quota
            time.sleep(2)
            
            # Pr√©parer les donn√©es pour le r√©sum√©
            data = []
            
            # En-t√™tes
            headers = ["Date", "Total vues", "Desktop", "Mobile", "Accueil", "√Ä propos", "Personnes", "Emplois", "Carri√®res"]
            data.append(headers)
            
            # Donn√©es totales
            totals = stats.get('totals', {})
            data.append([
                stats.get('date'),
                totals.get('total_page_views', 0),
                totals.get('total_desktop_views', 0),
                totals.get('total_mobile_views', 0),
                totals.get('total_overview_views', 0),
                totals.get('total_about_views', 0),
                totals.get('total_people_views', 0),
                totals.get('total_jobs_views', 0),
                totals.get('total_careers_views', 0)
            ])
            
            # Mettre √† jour la feuille avec les donn√©es
            safe_sheets_operation(sheet.update, data, 'A1')
            
            # Attendre un peu avant le formatage
            time.sleep(1)
            
            # Formater les en-t√™tes
            safe_sheets_operation(sheet.format, 'A1:I1', {
                "textFormat": {"bold": True},
                "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9}
            })
            
            # Attendre un peu avant le prochain formatage
            time.sleep(1)
            
            # Appliquer le formatage pour Looker
            self.format_sheet_for_looker(sheet, headers)
            
            return sheet
        except Exception as e:
            print(f"   Erreur lors de la pr√©paration de la feuille de r√©sum√©: {e}")
            return None
    
    def prepare_and_update_detail_sheets(self, stats):
        """Pr√©pare et met √† jour les feuilles d√©taill√©es pour chaque cat√©gorie"""
        try:
            # Ajouter un d√©lai plus long entre les mises √† jour pour √©viter les probl√®mes de quota
            print("   üìä Mise √† jour des feuilles d√©taill√©es...")
            
            self._update_country_sheet(stats)
            print("   ‚è≥ Attente de 10 secondes pour √©viter les quotas...")
            time.sleep(10)  # Attendre plus longtemps entre chaque mise √† jour
            
            self._update_seniority_sheet(stats)
            print("   ‚è≥ Attente de 10 secondes pour √©viter les quotas...")
            time.sleep(10)
            
            self._update_industry_sheet(stats)
            
        except Exception as e:
            print(f"   Erreur lors de la mise √† jour des feuilles d√©taill√©es: {e}")
    
    def _update_country_sheet(self, stats):
        """Met √† jour la feuille des statistiques par pays"""
        try:
            print("   üìç Mise √† jour de la feuille 'Par Pays'...")
            
            # V√©rifier si la feuille existe d√©j√†
            try:
                sheet = self.spreadsheet.worksheet("Par Pays")
            except gspread.exceptions.WorksheetNotFound:
                try:
                    sheet = self.spreadsheet.worksheet("Sheet2")
                    safe_sheets_operation(sheet.update_title, "Par Pays")
                    print("   Feuille par d√©faut 'Sheet2' renomm√©e en 'Par Pays'")
                except gspread.exceptions.WorksheetNotFound:
                    sheet = safe_sheets_operation(self.spreadsheet.add_worksheet, title="Par Pays", rows=100, cols=10)
                    print("   Nouvelle feuille 'Par Pays' cr√©√©e")
            
            # Nettoyer la feuille
            safe_sheets_operation(sheet.clear)
            time.sleep(2)
            
            # Pr√©parer les donn√©es
            data = []
            headers = ["Date", "Pays", "Code pays", "Total vues", "Desktop", "Mobile", "Accueil", "√Ä propos", "Personnes", "Emplois"]
            data.append(headers)
            
            date = stats['date']
            
            # Trier par nombre de vues d√©croissant
            country_entries = []
            for country_code, values in stats['by_country'].items():
                country_entries.append((
                    values['name'],
                    country_code,
                    values['total_views'],
                    values['desktop_views'],
                    values['mobile_views'],
                    values['overview_views'],
                    values['about_views'],
                    values['people_views'],
                    values['jobs_views']
                ))
            
            # Trier par nombre de vues (d√©croissant)
            country_entries.sort(key=lambda x: x[2], reverse=True)
            
            # Ajouter √† la liste de donn√©es
            for entry in country_entries:
                data.append([date] + list(entry))
            
            # Mettre √† jour la feuille avec les donn√©es
            if data:
                safe_sheets_operation(sheet.update, data, 'A1')
                time.sleep(1)
            
            # Formater les en-t√™tes
            safe_sheets_operation(sheet.format, 'A1:J1', {
                "textFormat": {"bold": True},
                "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9}
            })
            time.sleep(1)
            
            # Appliquer le formatage pour Looker
            self.format_sheet_for_looker(sheet, headers)
            
        except Exception as e:
            print(f"   Erreur lors de la mise √† jour de la feuille des pays: {e}")
    
    def _update_seniority_sheet(self, stats):
        """Met √† jour la feuille des statistiques par s√©niorit√©"""
        try:
            print("   üëî Mise √† jour de la feuille 'Par S√©niorit√©'...")
            
            # V√©rifier si la feuille existe d√©j√†
            try:
                sheet = self.spreadsheet.worksheet("Par S√©niorit√©")
            except gspread.exceptions.WorksheetNotFound:
                try:
                    sheet = self.spreadsheet.worksheet("Sheet3")
                    safe_sheets_operation(sheet.update_title, "Par S√©niorit√©")
                    print("   Feuille par d√©faut 'Sheet3' renomm√©e en 'Par S√©niorit√©'")
                except gspread.exceptions.WorksheetNotFound:
                    sheet = safe_sheets_operation(self.spreadsheet.add_worksheet, title="Par S√©niorit√©", rows=100, cols=10)
                    print("   Nouvelle feuille 'Par S√©niorit√©' cr√©√©e")
            
            # Nettoyer la feuille
            safe_sheets_operation(sheet.clear)
            time.sleep(2)
            
            # Pr√©parer les donn√©es
            data = []
            headers = ["Date", "Niveau", "Description", "Total vues", "Desktop", "Mobile", "Accueil", "√Ä propos", "Personnes", "Emplois"]
            data.append(headers)
            
            date = stats['date']
            
            # Trier par niveau de s√©niorit√© (ordre croissant)
            seniority_entries = []
            for seniority_id, values in stats['by_seniority'].items():
                try:
                    level = int(seniority_id)
                except ValueError:
                    level = 999  # Pour les valeurs non num√©riques
                
                seniority_entries.append((
                    level,
                    values['name'],
                    values['total_views'],
                    values['desktop_views'],
                    values['mobile_views'],
                    values['overview_views'],
                    values['about_views'],
                    values['people_views'],
                    values['jobs_views']
                ))
            
            # Trier par niveau
            seniority_entries.sort(key=lambda x: x[0])
            
            # Ajouter √† la liste de donn√©es
            for entry in seniority_entries:
                data.append([date, entry[0], entry[1]] + list(entry[2:]))
            
            # Mettre √† jour la feuille avec les donn√©es
            if data:
                safe_sheets_operation(sheet.update, data, 'A1')
                time.sleep(1)
            
            # Formater les en-t√™tes
            safe_sheets_operation(sheet.format, 'A1:J1', {
                "textFormat": {"bold": True},
                "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9}
            })
            time.sleep(1)
            
            # Appliquer le formatage pour Looker (la colonne Niveau est num√©rique ici)
            headers_modified = headers.copy()
            self.format_sheet_for_looker(sheet, headers_modified)
            
            # Formater sp√©cifiquement la colonne Niveau comme nombre
            safe_sheets_operation(sheet.format, 'B2:B', {
                "numberFormat": {
                    "type": "NUMBER",
                    "pattern": "0"
                }
            })
            
        except Exception as e:
            print(f"   Erreur lors de la mise √† jour de la feuille des s√©niorit√©s: {e}")
    
    def _update_industry_sheet(self, stats):
        """Met √† jour la feuille des statistiques par industrie"""
        try:
            print("   üè≠ Mise √† jour de la feuille 'Par Industrie'...")
            
            # V√©rifier si la feuille existe d√©j√†
            try:
                sheet = self.spreadsheet.worksheet("Par Industrie")
            except gspread.exceptions.WorksheetNotFound:
                try:
                    sheet = self.spreadsheet.worksheet("Sheet4")
                    safe_sheets_operation(sheet.update_title, "Par Industrie")
                    print("   Feuille par d√©faut 'Sheet4' renomm√©e en 'Par Industrie'")
                except gspread.exceptions.WorksheetNotFound:
                    sheet = safe_sheets_operation(self.spreadsheet.add_worksheet, title="Par Industrie", rows=1000, cols=10)
                    print("   Nouvelle feuille 'Par Industrie' cr√©√©e")
            
            # Nettoyer la feuille
            safe_sheets_operation(sheet.clear)
            time.sleep(2)
            
            # Pr√©parer les donn√©es
            data = []
            headers = ["Date", "Industrie ID", "Nom de l'industrie", "Total vues", "Desktop", "Mobile", "Accueil", "√Ä propos", "Personnes", "Emplois"]
            data.append(headers)
            
            date = stats['date']
            
            # Trier par nombre de vues (d√©croissant)
            industry_entries = []
            for industry_id, values in stats['by_industry'].items():
                industry_entries.append((
                    industry_id,
                    values['name'],
                    values['total_views'],
                    values['desktop_views'],
                    values['mobile_views'],
                    values['overview_views'],
                    values['about_views'],
                    values['people_views'],
                    values['jobs_views']
                ))
            
            # Trier par nombre de vues
            industry_entries.sort(key=lambda x: x[2], reverse=True)
            
            # Ajouter √† la liste de donn√©es
            for entry in industry_entries:
                data.append([date] + list(entry))
            
            # Mettre √† jour la feuille avec les donn√©es
            if data:
                safe_sheets_operation(sheet.update, data, 'A1')
                time.sleep(1)
            
            # Formater les en-t√™tes
            safe_sheets_operation(sheet.format, 'A1:J1', {
                "textFormat": {"bold": True},
                "backgroundColor": {"red": 0.9, "green": 0.9, "blue": 0.9}
            })
            time.sleep(1)
            
            # Appliquer le formatage pour Looker
            self.format_sheet_for_looker(sheet, headers)
            
        except Exception as e:
            print(f"   Erreur lors de la mise √† jour de la feuille des industries: {e}")
    
    def add_page_statistics(self, stats):
        """Ajoute les statistiques de vues de page"""
        if not self.connect():
            print("   Impossible de se connecter √† Google Sheets. V√©rifiez vos credentials.")
            return False
            
        # V√©rifier les permissions de partage pour s'assurer que l'admin a toujours acc√®s
        self.ensure_admin_access()
        
        # Attendre un peu avant de commencer les mises √† jour
        time.sleep(2)
        
        # Mettre √† jour les feuilles
        summary_sheet = self.prepare_and_update_summary_sheet(stats)
        if summary_sheet:
            print("   ‚úÖ Feuille de r√©sum√© mise √† jour avec succ√®s")
            # Attendre avant de passer aux feuilles d√©taill√©es
            print("   ‚è≥ Attente de 5 secondes avant les feuilles d√©taill√©es...")
            time.sleep(5)
            
            self.prepare_and_update_detail_sheets(stats)
        else:
            print("   ‚ùå √âchec de la mise √† jour de la feuille de r√©sum√©")
            return False
        
        # URL du spreadsheet
        sheet_url = f"https://docs.google.com/spreadsheets/d/{self.spreadsheet.id}"
        print(f"   URL du tableau: {sheet_url}")
        
        return True


def verify_token(access_token):
    """V√©rifie si le token d'acc√®s est valide"""
    headers = {
        "Authorization": f"Bearer {access_token}",
        "X-Restli-Protocol-Version": "2.0.0",
        "LinkedIn-Version": "202312"
    }
    
    url = "https://api.linkedin.com/v2/me"
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            return True, response.json()
        else:
            return False, f"Erreur {response.status_code}: {response.text}"
    except Exception as e:
        return False, str(e)


class MultiOrganizationPageStatsTracker:
    """Gestionnaire pour les statistiques de pages de plusieurs organisations LinkedIn"""
    
    def __init__(self, config_file='organizations_config.json'):
        """Initialise le tracker multi-organisations"""
        self.config_file = config_file
        self.organizations = self.load_organizations()
        self.access_token = os.getenv("LINKEDIN_ACCESS_TOKEN", "").strip("'")
        self.admin_email = os.getenv("GOOGLE_ADMIN_EMAIL", "byteberry.analytics@gmail.com")
        self.page_stats_mapping_file = 'page_stats_mapping.json'
        
    def load_organizations(self):
        """Charge la configuration des organisations depuis un fichier JSON"""
        try:
            # D'abord essayer de charger depuis un fichier local
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            
            # Sinon, charger depuis une variable d'environnement
            orgs_json = os.getenv("LINKEDIN_ORGANIZATIONS_CONFIG")
            if orgs_json:
                return json.loads(orgs_json)
            
            # Configuration par d√©faut
            print("Aucune configuration trouv√©e, utilisation de la configuration par d√©faut")
            return []
            
        except Exception as e:
            print(f"Erreur lors du chargement de la configuration: {e}")
            return []
    
    def get_sheet_info_for_org(self, org_id, org_name):
        """R√©cup√®re ou cr√©e l'ID et le nom du Google Sheet pour une organisation"""
        try:
            if os.path.exists(self.page_stats_mapping_file):
                with open(self.page_stats_mapping_file, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
            else:
                mapping = {}
            
            # Si l'organisation a d√©j√† un sheet ID, le retourner
            if org_id in mapping:
                print(f"   üìÇ R√©utilisation du Google Sheet existant")
                return mapping[org_id]['sheet_id'], mapping[org_id]['sheet_name']
            
            # Sinon, utiliser le nom par d√©faut
            clean_name = org_name.replace(' ', '_').replace('‚Ñ¢', '').replace('/', '_')
            sheet_name = f"LinkedIn_Page_Stats_{clean_name}_{org_id}"
            
            # Stocker le mapping pour la prochaine fois
            mapping[org_id] = {
                'sheet_name': sheet_name,
                'sheet_id': None,  # Sera mis √† jour apr√®s cr√©ation
                'org_name': org_name
            }
            
            with open(self.page_stats_mapping_file, 'w', encoding='utf-8') as f:
                json.dump(mapping, f, indent=2, ensure_ascii=False)
            
            return None, sheet_name
            
        except Exception as e:
            print(f"Erreur dans la gestion du mapping: {e}")
            clean_name = org_name.replace(' ', '_').replace('‚Ñ¢', '').replace('/', '_')
            sheet_name = f"LinkedIn_Page_Stats_{clean_name}_{org_id}"
            return None, sheet_name
    
    def update_sheet_mapping(self, org_id, sheet_id):
        """Met √† jour le mapping avec l'ID du sheet cr√©√©"""
        try:
            if os.path.exists(self.page_stats_mapping_file):
                with open(self.page_stats_mapping_file, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
            else:
                mapping = {}
            
            if org_id in mapping:
                mapping[org_id]['sheet_id'] = sheet_id
                mapping[org_id]['sheet_url'] = f"https://docs.google.com/spreadsheets/d/{sheet_id}"
                
                with open(self.page_stats_mapping_file, 'w', encoding='utf-8') as f:
                    json.dump(mapping, f, indent=2, ensure_ascii=False)
                    
        except Exception as e:
            print(f"Erreur lors de la mise √† jour du mapping: {e}")
    
    def process_all_organizations(self):
        """Traite toutes les organisations configur√©es"""
        if not self.access_token:
            print("Erreur: LINKEDIN_ACCESS_TOKEN manquant")
            return False
        
        # V√©rifier le token une seule fois
        print("\n--- V√©rification du token ---")
        is_valid, result = verify_token(self.access_token)
        
        if not is_valid:
            print(f"‚ùå Token invalide: {result}")
            return False
        
        print("‚úÖ Token valide!")
        user_info = result
        print(f"   Utilisateur: {user_info.get('localizedFirstName', '')} {user_info.get('localizedLastName', '')}")
        
        # Traiter chaque organisation
        results = []
        total_orgs = len(self.organizations)
        successful_urls = []
        
        for idx, org in enumerate(self.organizations, 1):
            org_id = org['id']
            org_name = org['name']
            
            print(f"\n{'='*60}")
            print(f"[{idx}/{total_orgs}] Traitement de: {org_name}")
            print(f"ID: {org_id}")
            print(f"{'='*60}")
            
            try:
                sheet_url = self.process_single_organization(org_id, org_name)
                if sheet_url:
                    results.append({
                        'org_id': org_id,
                        'org_name': org_name,
                        'success': True,
                        'sheet_url': sheet_url,
                        'timestamp': datetime.now().isoformat()
                    })
                    successful_urls.append({
                        'name': org_name,
                        'url': sheet_url
                    })
                else:
                    results.append({
                        'org_id': org_id,
                        'org_name': org_name,
                        'success': False,
                        'timestamp': datetime.now().isoformat()
                    })
                    
                # Attendre entre chaque organisation pour √©viter les probl√®mes de quota
                if idx < total_orgs:  # Ne pas attendre apr√®s la derni√®re organisation
                    print(f"   ‚è≥ Attente de 15 secondes avant la prochaine organisation...")
                    time.sleep(15)
                    
            except Exception as e:
                print(f"‚ùå Erreur lors du traitement de {org_name}: {e}")
                results.append({
                    'org_id': org_id,
                    'org_name': org_name,
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
        
        # R√©sum√©
        print(f"\n{'='*60}")
        print("R√âSUM√â DU TRAITEMENT - STATISTIQUES DE PAGES")
        print(f"{'='*60}")
        
        successful = sum(1 for r in results if r['success'])
        failed = len(results) - successful
        
        print(f"‚úÖ Organisations trait√©es avec succ√®s: {successful}/{total_orgs}")
        if failed > 0:
            print(f"‚ùå Organisations en √©chec: {failed}/{total_orgs}")
        
        if failed > 0:
            print("\nD√©tail des √©checs:")
            for r in results:
                if not r['success']:
                    error_msg = r.get('error', 'Erreur inconnue')
                    print(f"  - {r['org_name']}: {error_msg}")
        
        # Afficher les URLs des sheets cr√©√©s
        if successful > 0:
            print("\nüìä Google Sheets de statistiques de pages cr√©√©s/mis √† jour:")
            if os.path.exists(self.page_stats_mapping_file):
                with open(self.page_stats_mapping_file, 'r', encoding='utf-8') as f:
                    mapping = json.load(f)
                
                for r in results:
                    if r['success'] and r['org_id'] in mapping:
                        sheet_info = mapping[r['org_id']]
                        if sheet_info.get('sheet_id'):
                            print(f"  - {r['org_name']}:")
                            url = sheet_info.get('sheet_url') or f"https://docs.google.com/spreadsheets/d/{sheet_info['sheet_id']}"
                            print(f"    {url}")
        
        return successful > 0
    
    def process_single_organization(self, org_id, org_name):
        """Traite une organisation unique"""
        # Obtenir le nom du sheet pour cette organisation
        sheet_id, sheet_name = self.get_sheet_info_for_org(org_id, org_name)
        
        print(f"\nüìä Google Sheet: {sheet_name}")
        
        # Initialisation du tracker
        tracker = LinkedInPageStatisticsTracker(self.access_token, org_id, sheet_name)
        
        # Obtention des statistiques
        print("\n1. R√©cup√©ration des statistiques de vues de page...")
        raw_stats = tracker.get_page_statistics()
        
        if raw_stats:
            # Traitement des donn√©es
            print("\n2. Analyse des donn√©es statistiques...")
            stats = tracker.parse_page_statistics(raw_stats)
            
            # Afficher un aper√ßu
            print("\nüìà Aper√ßu des statistiques:")
            totals = stats.get('totals', {})
            print(f"   Total vues: {totals.get('total_page_views', 0)}")
            print(f"   Vues desktop: {totals.get('total_desktop_views', 0)}")
            print(f"   Vues mobile: {totals.get('total_mobile_views', 0)}")
            print(f"   Pays uniques: {len(stats.get('by_country', {}))}")
            print(f"   Industries repr√©sent√©es: {len(stats.get('by_industry', {}))}")
            
            # Chemin vers les credentials
            credentials_path = Path(__file__).resolve().parent / 'credentials' / 'service_account_credentials.json'
            
            # Pour Google Cloud Run, utiliser le chemin mont√©
            if os.getenv('K_SERVICE'):
                credentials_path = Path('/app/credentials/service_account_credentials.json')
            
            if not credentials_path.exists():
                # Essayer de cr√©er les credentials depuis une variable d'environnement
                creds_json = os.getenv('GOOGLE_SERVICE_ACCOUNT_JSON')
                if creds_json:
                    credentials_path.parent.mkdir(parents=True, exist_ok=True)
                    with open(credentials_path, 'w') as f:
                        f.write(creds_json)
                    print("   ‚úÖ Credentials cr√©√©s depuis la variable d'environnement")
                else:
                    print(f"   ‚ùå Erreur: Fichier de credentials non trouv√©: {credentials_path}")
                    return None
            else:
                print("   ‚úÖ Credentials trouv√©s")
            
            # Export vers Google Sheets
            print("\n3. Export vers Google Sheets...")
            exporter = GoogleSheetsExporter(tracker.sheet_name, credentials_path, self.admin_email)
            success = exporter.add_page_statistics(stats)
            
            if success and exporter.spreadsheet:
                # Mettre √† jour le mapping avec l'ID du sheet
                self.update_sheet_mapping(org_id, exporter.spreadsheet.id)
                sheet_url = f"https://docs.google.com/spreadsheets/d/{exporter.spreadsheet.id}"
                print(f"\n‚úÖ Export r√©ussi pour {org_name}!")
                print(f"üìä URL du Sheet: {sheet_url}")
                return sheet_url
            else:
                print(f"\n‚ùå √âchec de l'export pour {org_name}")
                return None
        else:
            print("   ‚ùå Impossible de r√©cup√©rer les statistiques de vues de page")
            return None


def main():
    """Fonction principale"""
    print("="*60)
    print("LINKEDIN MULTI-ORGANISATION PAGE STATISTICS TRACKER")
    print("="*60)
    print(f"Date d'ex√©cution: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Cr√©er le tracker
    tracker = MultiOrganizationPageStatsTracker()
    
    if not tracker.organizations:
        print("\n‚ùå Aucune organisation configur√©e!")
        print("\nPour configurer des organisations:")
        print("1. Lancez d'abord: python3 discover_organizations.py")
        print("2. Ou cr√©ez manuellement 'organizations_config.json' avec le format:")
        print(json.dumps([
            {"id": "123456", "name": "Entreprise A"},
            {"id": "789012", "name": "Entreprise B"}
        ], indent=2))
        sys.exit(1)
    
    print(f"\nüìã Organisations configur√©es: {len(tracker.organizations)}")
    for org in tracker.organizations:
        print(f"   - {org['name']} (ID: {org['id']})")
    
    print(f"\n‚öôÔ∏è  Configuration:")
    print(f"   - Email admin: {tracker.admin_email}")
    print(f"   - Type de donn√©es: Statistiques par pays, s√©niorit√© et industrie")
    
    # Demander confirmation si plus de 5 organisations
    if len(tracker.organizations) > 5:
        print(f"\n‚ö†Ô∏è  Attention: {len(tracker.organizations)} organisations √† traiter.")
        print("   Cela peut prendre du temps et consommer des quotas API.")
        response = input("   Continuer ? (o/N): ")
        if response.lower() != 'o':
            print("Annul√©.")
            sys.exit(0)
    
    print("\nüöÄ D√©marrage du traitement des statistiques de pages...")
    print("‚è≥ Note: Le traitement inclut des d√©lais pour respecter les quotas Google Sheets")
    
    # Lancer le traitement
    start_time = datetime.now()
    success = tracker.process_all_organizations()
    end_time = datetime.now()
    
    # Afficher le temps d'ex√©cution
    duration = end_time - start_time
    minutes = int(duration.total_seconds() // 60)
    seconds = int(duration.total_seconds() % 60)
    
    print(f"\n‚è±Ô∏è  Temps d'ex√©cution: {minutes}m {seconds}s")
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()